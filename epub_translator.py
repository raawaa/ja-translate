#!/usr/bin/env python3
"""
iFlow CLI æ—¥æ–‡ EPUB ç¿»è¯‘å™¨ï¼ˆä¸¥æ ¼éµå¾ªç”¨æˆ· workflowï¼‰
ä½œè€…ï¼šQwen + ç”¨æˆ·è§„èŒƒ
"""

import asyncio
import json
import os
import re
import time
import traceback
import logging
from pathlib import Path
from typing import List, Dict, Optional
from iflow_sdk import IFlowClient, AssistantMessage, TaskFinishMessage, TimeoutError as SDKTimeoutError, ToolCallMessage, PlanMessage, IFlowOptions, StopReason

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()

# ======================
# å…¨å±€æ—¥å¿—é…ç½®
# ======================
# å¯ç”¨è¯¦ç»†æ—¥å¿—ä»¥ä¾¿è°ƒè¯• - æŒ‰ç…§iFlow CLI SDKæ–‡æ¡£æœ€ä½³å®è·µ
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('debug.log', encoding='utf-8')
    ]
)

# ======================
# å…¨å±€é…ç½®å¸¸é‡
# ======================
SOURCE_ROOT = Path("source")
TRANSLATED_ROOT = Path("translated")
SOURCE_OEBPS = SOURCE_ROOT / "OEBPS"  # ç”¨äºå‘åå…¼å®¹
SOURCE_DIR = SOURCE_OEBPS  # å‘åå…¼å®¹ï¼šæŒ‡å‘ source/OEBPS
TRANSLATED_DIR = TRANSLATED_ROOT  # å‘åå…¼å®¹ï¼šæŒ‡å‘ translated
TEMP_DIR = Path("temp")  # è¿‡ç¨‹æ€§æ–‡ä»¶å­˜æ”¾ç›®å½•
CHECKLIST_FILE = TEMP_DIR / "translate-checklist.md"
GLOSSARY_FILE = "glossary.md"  # æœ¯è¯­è¡¨ä¿æŒåœ¨æ ¹ç›®å½•
PROGRESS_FILE = TEMP_DIR / "progress.json"
ERROR_LOG_FILE = TEMP_DIR / "error_log.json"
NEW_TERMS_FILE = TEMP_DIR / "new_terms.json"

MAX_RETRY = 3
TIMEOUT_SEC = 60.0
IFLOW_TIMEOUT = 600.0  # iFlowå®¢æˆ·ç«¯è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
QUALITY_CHECK_INTERVAL = 5

# èµ„æºç›‘æ§é…ç½®
MEMORY_MONITOR_INTERVAL = 300  # å†…å­˜ç›‘æ§é—´éš”ï¼ˆç§’ï¼‰
MEMORY_WARNING_THRESHOLD = 0.8  # å†…å­˜ä½¿ç”¨è­¦å‘Šé˜ˆå€¼ï¼ˆ80%ï¼‰
MAX_MEMORY_MB = 2048  # æœ€å¤§å…è®¸å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰
CLEANUP_INTERVAL = 600  # èµ„æºæ¸…ç†é—´éš”ï¼ˆç§’ï¼‰

# æ—¥å¿—ç³»ç»Ÿé…ç½®
LOG_LEVEL = "INFO"  # æ—¥å¿—çº§åˆ«: DEBUG, INFO, WARNING, ERROR
LOG_FILE = TEMP_DIR / "translation.log"  # æ—¥å¿—æ–‡ä»¶è·¯å¾„
LOG_MAX_SIZE = 10 * 1024 * 1024  # æ—¥å¿—æ–‡ä»¶æœ€å¤§å¤§å°ï¼ˆ10MBï¼‰
LOG_BACKUP_COUNT = 5  # æ—¥å¿—æ–‡ä»¶å¤‡ä»½æ•°é‡
CONNECTION_STATUS_FILE = TEMP_DIR / "connection_status.json"  # è¿æ¥çŠ¶æ€è®°å½•æ–‡ä»¶

# ======================
# iFlowè¿æ¥ç®¡ç†å™¨
# ======================

class IFlowConnectionManager:
    """iFlowè¿æ¥ç®¡ç†å™¨ï¼Œæä¾›è‡ªåŠ¨é‡è¿å’ŒçŠ¶æ€ç›‘æ§åŠŸèƒ½"""
    
    def __init__(self, timeout=600.0, max_reconnect_attempts=5, logger=None):
        self.timeout = timeout
        self.max_reconnect_attempts = max_reconnect_attempts
        self.client = None
        self.is_connected = False
        self.connection_stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'reconnections': 0,
            'last_activity': None,
            'connection_start_time': None
        }
        self.logger = logger or self._setup_logger()
    
    def _setup_logger(self):
        """è®¾ç½®è¿æ¥ç®¡ç†å™¨çš„æ—¥å¿—è®°å½•"""
        import logging
        logger = logging.getLogger('IFlowConnectionManager')
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    async def _check_and_restart_iflow_process(self):
        """æ£€æŸ¥å¹¶é‡å¯iFlowè¿›ç¨‹"""
        import subprocess
        import re
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰iFlowè¿›ç¨‹åœ¨è¿è¡Œ
            result = subprocess.run(
                ["lsof", "-i", ":8090"],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                # æ‰¾åˆ°è¿›ç¨‹ï¼Œå°è¯•æ€æ­»
                self.logger.warning("æ£€æµ‹åˆ°iFlowè¿›ç¨‹ä»åœ¨è¿è¡Œï¼Œå°è¯•é‡å¯...")
                
                # æå–PIDå¹¶æ€æ­»è¿›ç¨‹
                pid_match = re.search(r'\d+', result.stdout)
                if pid_match:
                    pid = int(pid_match.group())
                    subprocess.run(["kill", "-9", str(pid)], check=True)
                    self.logger.info(f"å·²æ€æ­»iFlowè¿›ç¨‹ (PID: {pid})")
                    await asyncio.sleep(2)  # ç­‰å¾…è¿›ç¨‹å®Œå…¨é€€å‡º
            
            self.logger.info("iFlowè¿›ç¨‹é‡å¯å‡†å¤‡å®Œæˆ")
        except Exception as e:
            self.logger.error(f"é‡å¯iFlowè¿›ç¨‹æ—¶å‡ºé”™: {e}")
            # å¿½ç•¥é”™è¯¯ï¼Œç»§ç»­å°è¯•è¿æ¥
            pass
    
    async def connect(self):
        """å»ºç«‹iFlowè¿æ¥"""
        from iflow_sdk import IFlowOptions
        
        # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
        api_key = os.getenv("IFLOW_API_KEY")
        
        # æ£€æŸ¥ API Key æ˜¯å¦é…ç½®
        if not api_key or api_key == "your_iflow_api_key_here":
            self.logger.error("iFlow API Key æœªé…ç½®ï¼")
            self.logger.error("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® IFLOW_API_KEY ç¯å¢ƒå˜é‡")
            self.logger.error("ç¤ºä¾‹: IFLOW_API_KEY=your_actual_api_key")
            raise ValueError("iFlow API Key æœªé…ç½®")
        
        url = os.getenv("IFLOW_WS_URL")
        
        for attempt in range(self.max_reconnect_attempts):
            try:
                self.logger.info(f"å°è¯•å»ºç«‹iFlowè¿æ¥ (ç¬¬ {attempt + 1}/{self.max_reconnect_attempts} æ¬¡)")
                
                # åœ¨ç¬¬ä¸€æ¬¡å°è¯•æˆ–åç»­å¤±è´¥æ—¶æ£€æŸ¥å¹¶é‡å¯iFlowè¿›ç¨‹
                if attempt > 0:
                    await self._check_and_restart_iflow_process()
                
                # é…ç½®é€‰é¡¹ï¼Œå¯ç”¨è¯¦ç»†æ—¥å¿— - æŒ‰ç…§iFlow CLI SDKæ–‡æ¡£
                options = IFlowOptions(
                    timeout=self.timeout,
                    log_level="DEBUG",
                    url=url if url else "ws://localhost:8090/acp",
                    auth_method_id="iflow",
                    auth_method_info={"api_key": api_key},
                    auto_start_process=True  # å¯ç”¨è‡ªåŠ¨è¿›ç¨‹ç®¡ç†
                )
                
                # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºIFlowé…ç½®ï¼ˆéšè—API Keyéƒ¨åˆ†å†…å®¹ï¼‰
                api_key_masked = f"{api_key[:5]}***" if api_key else "None"
                self.logger.debug(f"åˆ›å»ºIFlowå®¢æˆ·ç«¯ - è¶…æ—¶: {self.timeout}s, æ—¥å¿—çº§åˆ«: DEBUG, API Key: {api_key_masked}, URL: {options.url}")
                
                # åˆ›å»ºå®¢æˆ·ç«¯
                self.client = IFlowClient(options)
                await self.client.__aenter__()
                
                self.is_connected = True
                self.connection_stats['connection_start_time'] = time.time()
                self.connection_stats['last_activity'] = time.time()
                
                # è®°å½•è¿æ¥æˆåŠŸäº‹ä»¶
                if hasattr(self.logger, 'log_connection_event'):
                    self.logger.log_connection_event('connection_established', {
                        'attempt': attempt + 1,
                        'timeout': self.timeout
                    })
                
                self.logger.info("iFlowè¿æ¥å»ºç«‹æˆåŠŸ")
                return True
                
            except Exception as e:
                self.logger.error(f"è¿æ¥å¤±è´¥ (ç¬¬ {attempt + 1} æ¬¡): {type(e).__name__}: {str(e)}")
                
                if attempt < self.max_reconnect_attempts - 1:
                    delay = 5 * (1.5 ** attempt)  # æŒ‡æ•°é€€é¿
                    self.logger.info(f"ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    await asyncio.sleep(delay)
                else:
                    self.logger.error("æ‰€æœ‰è¿æ¥å°è¯•å‡å·²å¤±è´¥")
                    raise e
        
        return False
    
    async def disconnect(self):
        """æ–­å¼€iFlowè¿æ¥"""
        self.is_connected = False
        
        # å…³é—­å®¢æˆ·ç«¯è¿æ¥
        if self.client:
            try:
                await self.client.__aexit__(None, None, None)
            except Exception as e:
                self.logger.warning(f"å…³é—­è¿æ¥æ—¶å‡ºé”™: {e}")
            finally:
                self.client = None
        
        self.logger.info("iFlowè¿æ¥å·²æ–­å¼€")
    
    async def reset_session(self):
        """é‡ç½®ä¼šè¯ï¼Œé‡æ–°åˆ›å»ºIFlowClientå®ä¾‹"""
        self.logger.info("é‡ç½®iFlowä¼šè¯...")
        
        # æ–­å¼€å½“å‰è¿æ¥
        await self.disconnect()
        
        # ç«‹å³é‡æ–°å»ºç«‹è¿æ¥ï¼Œä¸ç­‰å¾…
        await self.connect()
        self.logger.info("iFlowä¼šè¯å·²é‡ç½®")
    
    async def _reconnect(self):
        """é‡æ–°è¿æ¥"""
        if not self.is_connected:
            return
        
        self.logger.warning("æ£€æµ‹åˆ°è¿æ¥é—®é¢˜ï¼Œå°è¯•é‡æ–°è¿æ¥...")
        self.connection_stats['reconnections'] += 1
        
        # å…ˆæ–­å¼€å½“å‰è¿æ¥
        await self.disconnect()
        
        # ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¿
        await asyncio.sleep(5)
        
        # å°è¯•é‡æ–°è¿æ¥
        await self.connect()
    
    async def send_message(self, message: str):
        """å‘é€æ¶ˆæ¯ï¼Œå¸¦æœ‰è¿æ¥çŠ¶æ€æ£€æŸ¥"""
        if not self.is_connected or not self.client:
            raise ConnectionError("iFlowè¿æ¥æœªå»ºç«‹")
        
        self.connection_stats['total_requests'] += 1
        self.connection_stats['last_activity'] = time.time()
        
        try:
            await self.client.send_message(message)
            self.connection_stats['successful_requests'] += 1
        except Exception as e:
            self.connection_stats['failed_requests'] += 1
            self.logger.error(f"å‘é€æ¶ˆæ¯å¤±è´¥: {e}")
            # å°è¯•é‡æ–°è¿æ¥
            await self._reconnect()
            raise e
    
    def get_message_iterator(self):
        """è·å–æ¶ˆæ¯è¿­ä»£å™¨"""
        if not self.is_connected or not self.client:
            raise ConnectionError("iFlowè¿æ¥æœªå»ºç«‹")
        return self.client.receive_messages()
    
    def get_connection_stats(self):
        """è·å–è¿æ¥ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.connection_stats.copy()
        if stats['connection_start_time']:
            stats['uptime'] = time.time() - stats['connection_start_time']
        stats['is_connected'] = self.is_connected
        return stats
    
    

# ======================
# èµ„æºç›‘æ§ç®¡ç†å™¨
# ======================

class ResourceMonitor:
    """èµ„æºç›‘æ§ç®¡ç†å™¨ï¼Œç›‘æ§å†…å­˜ä½¿ç”¨å’Œç³»ç»Ÿèµ„æº"""
    
    def __init__(self, max_memory_mb=MAX_MEMORY_MB, warning_threshold=MEMORY_WARNING_THRESHOLD):
        self.max_memory_mb = max_memory_mb
        self.warning_threshold = warning_threshold
        self.monitoring = False
        self.monitor_task = None
        self.logger = self._setup_logger()
        self.memory_history = []
        self.cleanup_callbacks = []
        
    def _setup_logger(self):
        """è®¾ç½®èµ„æºç›‘æ§å™¨çš„æ—¥å¿—è®°å½•"""
        import logging
        logger = logging.getLogger('ResourceMonitor')
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger
    
    def get_memory_usage(self):
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        try:
            import psutil
            process = psutil.Process()
            memory_info = process.memory_info()
            memory_mb = memory_info.rss / 1024 / 1024  # è½¬æ¢ä¸ºMB
            memory_percent = memory_mb / self.max_memory_mb
            
            return {
                'memory_mb': memory_mb,
                'memory_percent': memory_percent,
                'max_memory_mb': self.max_memory_mb,
                'timestamp': time.time()
            }
        except ImportError:
            # å¦‚æœæ²¡æœ‰psutilï¼Œä½¿ç”¨ç®€å•çš„å†…å­˜ç›‘æ§
            import resource
            memory_kb = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
            # åœ¨Windowsä¸Šï¼Œru_maxrssä»¥å­—èŠ‚ä¸ºå•ä½ï¼›åœ¨Unixä¸Šä»¥KBä¸ºå•ä½
            if os.name == 'nt':
                memory_mb = memory_kb / 1024 / 1024
            else:
                memory_mb = memory_kb / 1024
            memory_percent = memory_mb / self.max_memory_mb
            
            return {
                'memory_mb': memory_mb,
                'memory_percent': memory_percent,
                'max_memory_mb': self.max_memory_mb,
                'timestamp': time.time(),
                'note': 'Using basic memory monitoring (psutil not available)'
            }
        except Exception as e:
            self.logger.error(f"è·å–å†…å­˜ä½¿ç”¨æƒ…å†µå¤±è´¥: {e}")
            return None
    
    def add_cleanup_callback(self, callback):
        """æ·»åŠ èµ„æºæ¸…ç†å›è°ƒå‡½æ•°"""
        self.cleanup_callbacks.append(callback)
    
    async def cleanup_resources(self):
        """æ‰§è¡Œèµ„æºæ¸…ç†"""
        self.logger.info("å¼€å§‹æ‰§è¡Œèµ„æºæ¸…ç†...")
        
        for callback in self.cleanup_callbacks:
            try:
                if asyncio.iscoroutinefunction(callback):
                    await callback()
                else:
                    callback()
                self.logger.debug(f"æ‰§è¡Œæ¸…ç†å›è°ƒ: {callback.__name__}")
            except Exception as e:
                self.logger.error(f"æ¸…ç†å›è°ƒ {callback.__name__} æ‰§è¡Œå¤±è´¥: {e}")
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        collected = gc.collect()
        self.logger.info(f"åƒåœ¾å›æ”¶å®Œæˆï¼Œå›æ”¶äº† {collected} ä¸ªå¯¹è±¡")
    
    async def _check_iflow_process(self):
        """æ£€æŸ¥iFlowè¿›ç¨‹çŠ¶æ€"""
        import subprocess
        try:
            # æ£€æŸ¥iFlowè¿›ç¨‹æ˜¯å¦åœ¨è¿è¡Œ
            result = subprocess.run(
                ["lsof", "-i", ":8090"],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                # iFlowè¿›ç¨‹åœ¨è¿è¡Œ
                pid_match = result.stdout.split()[1] if len(result.stdout.split()) > 1 else "unknown"
                self.logger.debug(f"iFlowè¿›ç¨‹æ­£åœ¨è¿è¡Œ (PID: {pid_match})")
                return True
            else:
                # iFlowè¿›ç¨‹æœªåœ¨è¿è¡Œ
                self.logger.warning("æ£€æµ‹åˆ°iFlowè¿›ç¨‹æœªè¿è¡Œ")
                return False
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥iFlowè¿›ç¨‹çŠ¶æ€æ—¶å‡ºé”™: {e}")
            return False
    
    async def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.monitoring:
            try:
                # æ£€æŸ¥iFlowè¿›ç¨‹çŠ¶æ€
                await self._check_iflow_process()
                
                # æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ
                memory_info = self.get_memory_usage()
                if memory_info:
                    self.memory_history.append(memory_info)
                    
                    # åªä¿ç•™æœ€è¿‘100æ¡è®°å½•
                    if len(self.memory_history) > 100:
                        self.memory_history = self.memory_history[-100:]
                    
                    # æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ
                    memory_percent = memory_info['memory_percent']
                    memory_mb = memory_info['memory_mb']
                    
                    if memory_percent > self.warning_threshold:
                        self.logger.warning(
                            f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory_percent:.1%} ({memory_mb:.1f}MB/{self.max_memory_mb}MB)"
                        )
                        
                        # å¦‚æœå†…å­˜ä½¿ç”¨è¶…è¿‡90%ï¼Œæ‰§è¡Œæ¸…ç†
                        if memory_percent > 0.9:
                            self.logger.error("å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡90%ï¼Œæ‰§è¡Œç´§æ€¥æ¸…ç†...")
                            await self.cleanup_resources()
                    
                    # å®šæœŸè¾“å‡ºå†…å­˜çŠ¶æ€
                    if len(self.memory_history) % 10 == 0:
                        self.logger.info(
                            f"å†…å­˜çŠ¶æ€: {memory_mb:.1f}MB ({memory_percent:.1%}), "
                            f"å³°å€¼å†…å­˜: {max(h['memory_mb'] for h in self.memory_history):.1f}MB"
                        )
                
                await asyncio.sleep(MEMORY_MONITOR_INTERVAL)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(f"èµ„æºç›‘æ§å¾ªç¯å‡ºé”™: {e}")
                await asyncio.sleep(60)  # å‡ºé”™åç­‰å¾…1åˆ†é’Ÿå†ç»§ç»­
    
    async def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if self.monitoring:
            return
        
        self.monitoring = True
        self.monitor_task = asyncio.create_task(self._monitor_loop())
        self.logger.info("èµ„æºç›‘æ§å·²å¯åŠ¨")
    
    async def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        if not self.monitoring:
            return
        
        self.monitoring = False
        
        if self.monitor_task:
            self.monitor_task.cancel()
            try:
                await self.monitor_task
            except asyncio.CancelledError:
                pass
        
        self.logger.info("èµ„æºç›‘æ§å·²åœæ­¢")
    
    def get_memory_stats(self):
        """è·å–å†…å­˜ç»Ÿè®¡ä¿¡æ¯"""
        if not self.memory_history:
            return None
        
        memory_values = [h['memory_mb'] for h in self.memory_history]
        return {
            'current_mb': memory_values[-1],
            'peak_mb': max(memory_values),
            'min_mb': min(memory_values),
            'avg_mb': sum(memory_values) / len(memory_values),
            'samples': len(memory_values),
            'max_memory_mb': self.max_memory_mb
        }

# ======================
# å¢å¼ºæ—¥å¿—ç³»ç»Ÿ
# ======================

class EnhancedLogger:
    """å¢å¼ºçš„æ—¥å¿—ç³»ç»Ÿï¼Œæ”¯æŒæ–‡ä»¶è¾“å‡ºã€æ—¥å¿—è½®è½¬å’Œè¿æ¥çŠ¶æ€è®°å½•"""
    
    def __init__(self, name="EPUBTranslator", log_file=LOG_FILE, log_level=LOG_LEVEL):
        self.name = name
        self.log_file = log_file
        self.log_level = getattr(logging, log_level.upper(), logging.INFO)
        self.connection_status_file = CONNECTION_STATUS_FILE
        self.logger = self._setup_logger()
        self.connection_status_history = []
        
    def _setup_logger(self):
        """è®¾ç½®å¢å¼ºçš„æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger(self.name)
        logger.setLevel(self.log_level)
        
        # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
        logger.handlers.clear()
        
        # åˆ›å»ºæ ¼å¼åŒ–å™¨
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'
        )
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(self.log_level)
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)
        
        # æ–‡ä»¶å¤„ç†å™¨ï¼ˆå¸¦è½®è½¬ï¼‰
        try:
            from logging.handlers import RotatingFileHandler
            file_handler = RotatingFileHandler(
                self.log_file,
                maxBytes=LOG_MAX_SIZE,
                backupCount=LOG_BACKUP_COUNT,
                encoding='utf-8'
            )
            file_handler.setLevel(self.log_level)
            file_handler.setFormatter(formatter)
            logger.addHandler(file_handler)
        except Exception as e:
            logger.warning(f"æ— æ³•åˆ›å»ºæ–‡ä»¶æ—¥å¿—å¤„ç†å™¨: {e}")
        
        return logger
    
    def log_connection_event(self, event_type, details=None):
        """è®°å½•è¿æ¥äº‹ä»¶"""
        timestamp = time.time()
        event = {
            'timestamp': timestamp,
            'datetime': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(timestamp)),
            'event_type': event_type,
            'details': details or {}
        }
        
        self.connection_status_history.append(event)
        
        # åªä¿ç•™æœ€è¿‘1000æ¡è®°å½•
        if len(self.connection_status_history) > 1000:
            self.connection_status_history = self.connection_status_history[-1000:]
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        self._save_connection_status()
        
        # è®°å½•æ—¥å¿—
        message = f"è¿æ¥äº‹ä»¶: {event_type}"
        if details:
            message += f" - {details}"
        
        if event_type in ['connection_lost', 'reconnection_failed']:
            self.logger.error(message)
        elif event_type in ['reconnecting', 'connection_unhealthy']:
            self.logger.warning(message)
        else:
            self.logger.info(message)
    
    def _save_connection_status(self):
        """ä¿å­˜è¿æ¥çŠ¶æ€åˆ°æ–‡ä»¶"""
        try:
            status_data = {
                'last_updated': time.time(),
                'last_updated_datetime': time.strftime('%Y-%m-%d %H:%M:%S'),
                'total_events': len(self.connection_status_history),
                'recent_events': self.connection_status_history[-50:],  # ä¿å­˜æœ€è¿‘50æ¡
                'summary': self._generate_connection_summary()
            }
            
            with open(self.connection_status_file, 'w', encoding='utf-8') as f:
                json.dump(status_data, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            self.logger.error(f"ä¿å­˜è¿æ¥çŠ¶æ€å¤±è´¥: {e}")
    
    def _generate_connection_summary(self):
        """ç”Ÿæˆè¿æ¥çŠ¶æ€æ‘˜è¦"""
        if not self.connection_status_history:
            return {}
        
        # ç»Ÿè®¡å„ç§äº‹ä»¶ç±»å‹
        event_counts = {}
        recent_events = self.connection_status_history[-100:]  # æœ€è¿‘100æ¡
        
        for event in recent_events:
            event_type = event['event_type']
            event_counts[event_type] = event_counts.get(event_type, 0) + 1
        
        # è®¡ç®—è¿æ¥ç¨³å®šæ€§
        total_events = len(recent_events)
        negative_events = sum(
            event_counts.get(t, 0) for t in 
            ['connection_lost', 'reconnection_failed', 'connection_unhealthy']
        )
        
        stability_score = max(0, (total_events - negative_events) / total_events) if total_events > 0 else 1.0
        
        return {
            'event_counts': event_counts,
            'stability_score': stability_score,
            'total_recent_events': total_events,
            'negative_events_ratio': negative_events / total_events if total_events > 0 else 0
        }
    
    def log_translation_progress(self, file_name, block_index, total_blocks, success=True, error_msg=None):
        """è®°å½•ç¿»è¯‘è¿›åº¦"""
        message = f"ç¿»è¯‘è¿›åº¦: {file_name} - å— {block_index + 1}/{total_blocks}"
        
        if success:
            self.logger.info(message)
        else:
            self.logger.error(f"{message} - å¤±è´¥: {error_msg}")
    
    def log_resource_usage(self, resource_info):
        """è®°å½•èµ„æºä½¿ç”¨æƒ…å†µ"""
        self.logger.info(
            f"èµ„æºä½¿ç”¨ - å†…å­˜: {resource_info.get('memory_mb', 0):.1f}MB "
            f"({resource_info.get('memory_percent', 0):.1%}), "
            f"è¿æ¥çŠ¶æ€: {resource_info.get('connection_status', 'unknown')}"
        )
    
    def log_error_with_context(self, error, context=None):
        """è®°å½•å¸¦ä¸Šä¸‹æ–‡çš„é”™è¯¯"""
        error_info = {
            'error_type': type(error).__name__,
            'error_message': str(error),
            'context': context,
            'timestamp': time.time(),
            'traceback': traceback.format_exc()
        }
        
        self.logger.error(
            f"é”™è¯¯è¯¦æƒ…: {error_info['error_type']} - {error_info['error_message']}\n"
            f"ä¸Šä¸‹æ–‡: {context}\n"
            f"å †æ ˆè·Ÿè¸ª: {error_info['traceback']}"
        )
        
        # ä¿å­˜é”™è¯¯åˆ°é”™è¯¯æ—¥å¿—æ–‡ä»¶
        try:
            error_log = load_json(ERROR_LOG_FILE, {"errors": []})
            error_log["errors"].append(error_info)
            
            # åªä¿ç•™æœ€è¿‘100ä¸ªé”™è¯¯
            if len(error_log["errors"]) > 100:
                error_log["errors"] = error_log["errors"][-100:]
            
            save_json(error_log, ERROR_LOG_FILE)
        except Exception as e:
            self.logger.error(f"ä¿å­˜é”™è¯¯æ—¥å¿—å¤±è´¥: {e}")
    
    def get_connection_report(self):
        """è·å–è¿æ¥çŠ¶æ€æŠ¥å‘Š"""
        if not self.connection_status_history:
            return "æš‚æ— è¿æ¥çŠ¶æ€è®°å½•"
        
        summary = self._generate_connection_summary()
        
        report = f"""
è¿æ¥çŠ¶æ€æŠ¥å‘Š
============
æ€»äº‹ä»¶æ•°: {summary['total_recent_events']}
ç¨³å®šæ€§è¯„åˆ†: {summary['stability_score']:.2%}
è´Ÿé¢äº‹ä»¶æ¯”ä¾‹: {summary['negative_events_ratio']:.2%}

äº‹ä»¶ç»Ÿè®¡:
"""
        
        for event_type, count in summary['event_counts'].items():
            report += f"  {event_type}: {count} æ¬¡\n"
        
        # æœ€è¿‘çš„äº‹ä»¶
        recent_events = self.connection_status_history[-10:]
        if recent_events:
            report += "\næœ€è¿‘äº‹ä»¶:\n"
            for event in recent_events:
                report += f"  {event['datetime']} - {event['event_type']}\n"
        
        return report
    
    # åŸºæœ¬æ—¥å¿—æ–¹æ³•ï¼Œå§”æ‰˜ç»™å†…éƒ¨logger
    def info(self, message, *args, **kwargs):
        """è®°å½•ä¿¡æ¯çº§åˆ«æ—¥å¿—"""
        self.logger.info(message, *args, **kwargs)
    
    def error(self, message, *args, **kwargs):
        """è®°å½•é”™è¯¯çº§åˆ«æ—¥å¿—"""
        self.logger.error(message, *args, **kwargs)
    
    def warning(self, message, *args, **kwargs):
        """è®°å½•è­¦å‘Šçº§åˆ«æ—¥å¿—"""
        self.logger.warning(message, *args, **kwargs)
    
    def debug(self, message, *args, **kwargs):
        """è®°å½•è°ƒè¯•çº§åˆ«æ—¥å¿—"""
        self.logger.debug(message, *args, **kwargs)
    
    def critical(self, message, *args, **kwargs):
        """è®°å½•ä¸¥é‡é”™è¯¯çº§åˆ«æ—¥å¿—"""
        self.logger.critical(message, *args, **kwargs)

# ======================
# ç›®å½•åˆå§‹åŒ–
# ======================

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
TRANSLATED_ROOT.mkdir(exist_ok=True)
TEMP_DIR.mkdir(exist_ok=True)


async def create_connection_manager_with_retry(max_retries=3, delay=5, timeout=600.0, logger=None):
    """åˆ›å»º IFlowConnectionManager å¹¶ä½¿ç”¨é‡è¯•æœºåˆ¶å¤„ç†è¿æ¥é—®é¢˜"""
    
    for attempt in range(max_retries):
        try:
            print(f"\n{'='*60}")
            print(f"ğŸ”— å°è¯•åˆ›å»º iFlow è¿æ¥ç®¡ç†å™¨ (ç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•)")
            print(f"â° è¿æ¥æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"âš™ï¸ è¶…æ—¶è®¾ç½®: {timeout}ç§’")
            
            connect_start = time.time()
            
            # åˆ›å»ºè¿æ¥ç®¡ç†å™¨
            connection_manager = IFlowConnectionManager(
                timeout=timeout,
                max_reconnect_attempts=max_retries,
                logger=logger
            )
            
            # å»ºç«‹è¿æ¥
            success = await connection_manager.connect()
            connect_duration = time.time() - connect_start
            
            if success:
                print(f"âœ… æˆåŠŸåˆ›å»º iFlow è¿æ¥ç®¡ç†å™¨ (è€—æ—¶ {connect_duration:.2f}ç§’)")
                
                # æ˜¾ç¤ºè¿æ¥ç»Ÿè®¡ä¿¡æ¯
                stats = connection_manager.get_connection_stats()
                print(f"ğŸ“Š è¿æ¥ç»Ÿè®¡: {stats}")
                print(f"{'='*60}\n")
                return connection_manager
            else:
                raise ConnectionError("è¿æ¥ç®¡ç†å™¨è¿æ¥å¤±è´¥")
                
        except Exception as e:
            connect_duration = time.time() - connect_start if 'connect_start' in locals() else 0
            print(f"âš ï¸ è¿æ¥ç®¡ç†å™¨åˆ›å»ºå¤±è´¥ (ç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•)")
            print(f"âŒ é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"âŒ é”™è¯¯è¯¦æƒ…: {str(e)}")
            print(f"â±ï¸ å°è¯•è€—æ—¶: {connect_duration:.2f}ç§’")
            
            if attempt < max_retries - 1:
                next_delay = delay * (1.5 ** attempt)
                print(f"â³ ç­‰å¾… {next_delay:.1f} ç§’åé‡è¯•...")
                await asyncio.sleep(next_delay)
            else:
                print("âŒ æ‰€æœ‰è¿æ¥ç®¡ç†å™¨åˆ›å»ºå°è¯•å‡å·²å¤±è´¥")
                print(f"{'='*60}\n")
                import traceback
                print("ğŸ“‹ å®Œæ•´é”™è¯¯å †æ ˆ:")
                traceback.print_exc()
                raise e

# ä¿ç•™åŸå‡½æ•°ä»¥å‘åå…¼å®¹ï¼Œä½†å†…éƒ¨ä½¿ç”¨æ–°çš„è¿æ¥ç®¡ç†å™¨
async def create_client_with_retry(max_retries=3, delay=5, timeout=600.0):
    """åˆ›å»º IFlowClient å¹¶ä½¿ç”¨é‡è¯•æœºåˆ¶å¤„ç†è¿æ¥é—®é¢˜ï¼ˆå‘åå…¼å®¹å‡½æ•°ï¼‰"""
    connection_manager = await create_connection_manager_with_retry(
        max_retries=max_retries,
        delay=delay,
        timeout=timeout
    )
    return connection_manager

# ======================
# è¾…åŠ©å‡½æ•°
# ======================

def load_glossary() -> Dict[str, str]:
    """åŠ è½½æœ¯è¯­è¡¨ï¼šæ—¥æ–‡ -> ä¸­æ–‡"""
    if not os.path.exists(GLOSSARY_FILE):
        return {}
    glossary = {}
    with open(GLOSSARY_FILE, 'r', encoding='utf-8') as f:
        lines = f.readlines()
        for line in lines[2:]:  # è·³è¿‡æ ‡é¢˜è¡Œ
            if '|' in line:
                parts = line.strip().split('|')
                if len(parts) >= 3:
                    ja = parts[1].strip()
                    zh = parts[2].strip()
                    if ja and zh:
                        glossary[ja] = zh
    return glossary

def save_json(data, filepath: str):
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def load_json(filepath: str, default):
    if os.path.exists(filepath):
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    return default

def should_translate_file(file_path: Path) -> bool:
    """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦éœ€è¦ç¿»è¯‘"""
    # åªç¿»è¯‘ OEBPS ç›®å½•ä¸‹çš„ç‰¹å®šæ–‡æœ¬æ–‡ä»¶
    if "OEBPS" not in file_path.parts:
        return False
    
    ext = file_path.suffix.lower()
    return ext in ['.html', '.xhtml', '.ncx', '.opf']

def extract_translatable_blocks(html: str) -> List[str]:
    """æå–æ‰€æœ‰å¯ç¿»è¯‘çš„ HTML å—ï¼ˆä¿ç•™æ ‡ç­¾ï¼‰"""
    # ä½¿ç”¨ BeautifulSoup ä»¥æ›´å®‰å…¨åœ°è§£æ HTMLï¼Œé¿å…æ­£åˆ™è¡¨è¾¾å¼å¤„ç†å¤æ‚ HTML æ—¶çš„é—®é¢˜
    try:
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(html, 'html.parser')
        elements = soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'div'])
        return [str(elem) for elem in elements]
    except ImportError:
        # å¦‚æœæ²¡æœ‰å®‰è£…BeautifulSoupï¼Œåˆ™ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
        # åŒ¹é… <p>, <h1>-<h6>, <div>ï¼ˆå¸¦ class çš„å¸¸è§æ­£æ–‡å®¹å™¨ï¼‰
        pattern = r'(<(p|h[1-6]|div)(?:\s[^>]*)?>.*?</\2>)'
        matches = re.findall(pattern, html, re.DOTALL | re.IGNORECASE)
        return [m[0] for m in matches]

def get_file_type(filename: str) -> str:
    """
    æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šæ–‡ä»¶ç±»å‹
    """
    if filename.endswith('.html') or filename.endswith('.xhtml'):
        return 'html'
    elif filename.endswith('.ncx'):
        return 'ncx'
    elif filename.endswith('.opf'):
        return 'opf'
    else:
        return 'other'

def build_context(blocks: List[str], idx: int) -> tuple:
    prev_block = blocks[idx - 1] if idx > 0 else ""
    curr_block = blocks[idx]
    next_block = blocks[idx + 1] if idx < len(blocks) - 1 else ""
    return prev_block, curr_block, next_block

def extract_translatable_blocks_ncx(content: str) -> List[str]:
    """æå–NCXæ–‡ä»¶ä¸­çš„å¯ç¿»è¯‘æ–‡æœ¬ï¼ˆç« èŠ‚æ ‡é¢˜ç­‰ï¼‰"""
    try:
        from xml.etree import ElementTree as ET
        root = ET.fromstring(content)
        
        # å®šä¹‰å‘½åç©ºé—´
        namespaces = {
            'ncx': 'http://www.daisy.org/z3986/2005/ncx/'
        }
        
        translatable_blocks = []
        
        # æå–æ‰€æœ‰<navLabel><text>ä¸­çš„å†…å®¹
        for nav_point in root.findall('.//ncx:navLabel', namespaces):
            text_elem = nav_point.find('ncx:text', namespaces)
            if text_elem is not None and text_elem.text and contains_japanese(text_elem.text or ""):
                # åŒ…å«å®Œæ•´çš„æ ‡ç­¾ç»“æ„ä»¥ä¾¿æ­£ç¡®æ›¿æ¢
                block = f"<text>{text_elem.text}</text>"
                translatable_blocks.append(block)
        
        return translatable_blocks
    except ET.ParseError as e:
        print(f"è§£æNCXæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
        import re
        matches = re.findall(r'<text>([^<]*)</text>', content)
        blocks = []
        for match in matches:
            if contains_japanese(match):
                blocks.append(f"<text>{match}</text>")
        return blocks
    except Exception as e:
        print(f"å¤„ç†NCXæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return []

def extract_translatable_blocks_opf(content: str) -> List[str]:
    """æå–OPFæ–‡ä»¶ä¸­çš„å¯ç¿»è¯‘å…ƒæ•°æ®"""
    try:
        from xml.etree import ElementTree as ET
        root = ET.fromstring(content)
        
        # å®šä¹‰å‘½åç©ºé—´
        namespaces = {
            'opf': 'http://www.idpf.org/2007/opf',
            'dc': 'http://purl.org/dc/elements/1.1/'
        }
        
        translatable_blocks = []
        
        # æå–æ‰€æœ‰å¯èƒ½åŒ…å«æ—¥æ–‡çš„å…ƒç´ 
        elements_to_check = [
            'dc:title', 'dc:creator', 'dc:subject', 
            'dc:description', 'dc:publisher', 'dc:contributor'
        ]
        
        for elem_name in elements_to_check:
            for elem in root.findall(f'.//{elem_name}', namespaces):
                if elem.text and contains_japanese(elem.text):
                    # ä¿ç•™æ ‡ç­¾ç»“æ„ï¼Œä¾¿äºåç»­æ›¿æ¢
                    tag_name = elem_name.split(':')[-1]  # è·å–æ ‡ç­¾åï¼ˆå»æ‰å‘½åç©ºé—´å‰ç¼€ï¼‰
                    block = f"<{tag_name}>{elem.text}</{tag_name}>"
                    translatable_blocks.append(block)
        
        return translatable_blocks
    except ET.ParseError as e:
        print(f"è§£æOPFæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        # å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
        import re
        matches = re.findall(r'<(?:dc:)?(title|creator|subject|description|publisher|contributor)>([^<]*)</(?:dc:)?\1>', content)
        blocks = []
        for tag, content in matches:
            if contains_japanese(content):
                blocks.append(f"<{tag}>{content}</{tag}>")
        return blocks
    except Exception as e:
        print(f"å¤„ç†OPFæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return []

def contains_japanese(text: str) -> bool:
    # åªæ£€æµ‹æ—¥è¯­ç‰¹æœ‰çš„å­—ç¬¦ï¼šå¹³å‡åå’Œç‰‡å‡å
    # ä¸åŒ…æ‹¬æ±‰å­—ï¼Œå› ä¸ºä¸­æ—¥æ±‰å­—å…±ç”¨ Unicode èŒƒå›´ï¼Œéš¾ä»¥å‡†ç¡®åŒºåˆ†
    return bool(re.search(r'[\u3040-\u309F\u30A0-\u30FF]', text))

def check_chinese_punctuation(text: str) -> bool:
    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ä¸­æ–‡æ ‡ç‚¹ï¼ˆç®€å•è§„åˆ™ï¼‰
    jp_punct = 'ã€‚ã€ãƒ»ã€Œã€ã€ã€ã€ã€‘ï¼ï¼Ÿ'
    for p in jp_punct:
        if p in text:
            return False
    return True

def update_checklist(file_list: List[str], progress_data: dict):
    """æ›´æ–° translate-checklist.md"""
    content = "# æ—¥æ–‡ä¹¦ç±ç¿»è¯‘è¿›åº¦è¿½è¸ª\n\n"
    
    # è·å–å…ƒæ•°æ®
    meta = progress_data.get("meta", {})
    total_files = meta.get("total_files", len(file_list))
    completed_files_count = meta.get("completed_files", 0)
    total_blocks = meta.get("total_blocks", 0)
    completed_blocks = meta.get("completed_blocks", 0)
    last_updated = meta.get("last_updated", time.strftime("%Y-%m-%d %H:%M:%S"))
    
    # æŒ‰ç±»å‹åˆ†ç»„æ–‡ä»¶
    html_files = [f for f in file_list if f.endswith('.html')]
    ncx_files = [f for f in file_list if f.endswith('.ncx')]
    opf_files = [f for f in file_list if f.endswith('.opf')]
    other_files = [f for f in file_list if f not in html_files + ncx_files + opf_files]

    if html_files:
        content += "## HTMLæ–‡ä»¶\n"
        for f in html_files:
            file_progress = progress_data.get("files", {}).get(f, {})
            is_completed = file_progress.get("is_completed", False)
            mark = "x" if is_completed else " "
            
            # æ·»åŠ å—çº§è¿›åº¦ä¿¡æ¯
            if not is_completed:
                completed_blocks_count = file_progress.get("completed_blocks", 0)
                total_blocks_count = file_progress.get("total_blocks", 0)
                if total_blocks_count > 0:
                    block_progress = f" ({completed_blocks_count}/{total_blocks_count} å—)"
                    content += f"- [{mark}] {f}{block_progress}\n"
                else:
                    content += f"- [{mark}] {f}\n"
            else:
                content += f"- [{mark}] {f}\n"
        content += "\n"

    if ncx_files:
        content += "## ç›®å½•æ–‡ä»¶\n"
        for f in ncx_files:
            file_progress = progress_data.get("files", {}).get(f, {})
            is_completed = file_progress.get("is_completed", False)
            mark = "x" if is_completed else " "
            content += f"- [{mark}] {f}\n"
        content += "\n"

    if opf_files:
        content += "## å…ƒæ•°æ®æ–‡ä»¶\n"
        for f in opf_files:
            file_progress = progress_data.get("files", {}).get(f, {})
            is_completed = file_progress.get("is_completed", False)
            mark = "x" if is_completed else " "
            content += f"- [{mark}] {f}\n"
        content += "\n"

    if other_files:
        content += "## å…¶ä»–æ–‡ä»¶\n"
        for f in other_files:
            file_progress = progress_data.get("files", {}).get(f, {})
            is_completed = file_progress.get("is_completed", True)  # å…¶ä»–æ–‡ä»¶é»˜è®¤ä¸ºå·²å®Œæˆ
            mark = "x" if is_completed else " "
            content += f"- [{mark}] {f}\n"
        content += "\n"

    content += "## ç¿»è¯‘è¿›åº¦ç»Ÿè®¡\n"
    total = len(file_list)
    done = completed_files_count
    percent = done / total * 100 if total > 0 else 0
    content += f"- æ€»æ–‡ä»¶æ•°: {total}ä¸ªæ–‡ä»¶\n"
    content += f"- å·²ç¿»è¯‘: {done}ä¸ª\n"
    content += f"- å¾…ç¿»è¯‘: {total - done}ä¸ª\n"
    content += f"- æ–‡ä»¶å®Œæˆåº¦: {percent:.1f}%\n"
    
    # æ·»åŠ å—çº§è¿›åº¦ç»Ÿè®¡
    if total_blocks > 0:
        block_percent = completed_blocks / total_blocks * 100 if total_blocks > 0 else 0
        content += f"- æ€»æ–‡æœ¬å—: {total_blocks}ä¸ª\n"
        content += f"- å·²ç¿»è¯‘å—: {completed_blocks}ä¸ª\n"
        content += f"- å—å®Œæˆåº¦: {block_percent:.1f}%\n"
    
    content += f"- æœ€åæ›´æ–°æ—¶é—´: {last_updated}\n"
    
    with open(CHECKLIST_FILE, 'w', encoding='utf-8') as f:
        f.write(content)

# ======================
# æ ¸å¿ƒç¿»è¯‘å‡½æ•°
# ======================

async def translate_block(
    connection_manager: IFlowConnectionManager,
    current_block: str,
    prev_block: str = "",
    next_block: str = "",
    glossary: Dict[str, str] = None,
    max_retries: int = MAX_RETRY
) -> str:
    """
    ç¿»è¯‘å•ä¸ª HTML å—ï¼ˆä½¿ç”¨è¿æ¥ç®¡ç†å™¨ï¼‰
    """
    # å…³é”®ä¿®æ”¹ï¼šæå–åŸå—çš„ HTML æ ‡ç­¾ç»“æ„
    original_tag = ""
    tag_name = ""
    content_inside_tag = ""
    leading_spaces = ""  # åˆå§‹åŒ–å¼€å¤´ç©ºæ ¼
    trailing_spaces = ""  # åˆå§‹åŒ–ç»“å°¾ç©ºæ ¼
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ ‡ç­¾å’Œå†…å®¹
    tag_match = re.match(r'<([a-z0-9]+)([^>]*)>(.*)</\1>$', current_block, re.DOTALL | re.IGNORECASE)
    if tag_match:
        tag_name = tag_match.group(1).lower()  # æ ‡ç­¾åç§°
        tag_attributes = tag_match.group(2)  # æ ‡ç­¾å±æ€§
        original_tag = f"<{tag_name}{tag_attributes}>"  # å®Œæ•´çš„å¼€å§‹æ ‡ç­¾
        closing_tag = f"</{tag_name}>"  # ç»“æŸæ ‡ç­¾
        content_inside_tag = tag_match.group(3)  # æ ‡ç­¾å†…çš„å†…å®¹
        
        # æå–å¹¶ä¿å­˜åŸå§‹å†…å®¹çš„å‰åç©ºæ ¼
        leading_spaces = re.match(r'^(\s+)', content_inside_tag, re.DOTALL)  # å¼€å¤´ç©ºæ ¼
        trailing_spaces = re.search(r'(\s+)$', content_inside_tag, re.DOTALL)  # ç»“å°¾ç©ºæ ¼
        leading_spaces = leading_spaces.group(1) if leading_spaces else ""  # ä¿å­˜å¼€å¤´ç©ºæ ¼
        trailing_spaces = trailing_spaces.group(1) if trailing_spaces else ""  # ä¿å­˜ç»“å°¾ç©ºæ ¼
    
    # æ„å»ºæœ¯è¯­æç¤º
    glossary_text = ""
    if glossary:
        terms = "\n".join([f"{ja} â†’ {zh}" for ja, zh in list(glossary.items())[:10]])  # é™åˆ¶é•¿åº¦
        glossary_text = f"\n\nè¯·ä¼˜å…ˆä½¿ç”¨ä»¥ä¸‹æœ¯è¯­ç¿»è¯‘ï¼š\n{terms}"

    # æ„å»ºä¸Šä¸‹æ–‡ï¼ˆæˆªæ–­é¿å…è¶…é•¿ï¼‰
    context_prompt = ""
    if prev_block or next_block:
        context_parts = []
        if prev_block:
            clean_prev = re.sub(r'<[^>]+>', '', prev_block)[:30]
            context_parts.append(f"å‰ä¸€æ®µï¼š{clean_prev}...")
        if next_block:
            clean_next = re.sub(r'<[^>]+>', '', next_block)[:30]
            context_parts.append(f"åä¸€æ®µï¼š{clean_next}...")
        context_prompt = "ä¸Šä¸‹æ–‡ï¼š" + "ï¼›".join(context_parts)

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—¥ä¸­ç¿»è¯‘ä¸“å®¶ï¼Œå¯¹ä¸¤ç§è¯­è¨€çš„ç»†å¾®å·®åˆ«ã€æ–‡åŒ–èƒŒæ™¯å’Œæƒ¯ç”¨è¡¨è¾¾æœ‰æ·±å…¥äº†è§£ã€‚è¯·ä¸¥æ ¼éµå®ˆï¼š
- ä»…è¾“å‡ºç¿»è¯‘åçš„ HTML æ®µè½ï¼Œä¸è¦ä»»ä½•è§£é‡Šã€æ³¨é‡Šæˆ–é¢å¤–æ–‡æœ¬
- ä¿æŒåŸå§‹ HTML æ ‡ç­¾ä¸å˜
- ä½¿ç”¨ä¸­æ–‡æ ‡ç‚¹ï¼ˆï¼Œã€‚ï¼ï¼Ÿï¼‰
- æ— æ—¥æ–‡å­—ç¬¦æ®‹ç•™
- å‡†ç¡®å¿ å®äºåŸæ–‡å«ä¹‰ï¼ŒåŒæ—¶ç¡®ä¿ä¸­æ–‡è¡¨è¾¾è‡ªç„¶æµç•…ï¼Œç¬¦åˆä¸­æ–‡é˜…è¯»ä¹ æƒ¯
- æ•æ‰åŸæ–‡çš„è¯­æ°”ã€æ–‡åŒ–ç»†å¾®å·®åˆ«å’Œéšå«æ„ä¹‰
- æ³¨æ„å¤„ç†æ•¬è¯­å’Œæ­£å¼ç¨‹åº¦ï¼Œåœ¨ä¸­æ–‡ä¸­é€‚å½“è°ƒæ•´
- è€ƒè™‘å¯èƒ½æ²¡æœ‰ç›´æ¥å¯¹ç­‰è¯çš„æ–‡åŒ–å¼•ç”¨å’Œè¡¨è¾¾{glossary_text}

{context_prompt}

ç°åœ¨ç¿»è¯‘ä»¥ä¸‹æ®µè½ï¼š
{current_block}
"""

    for attempt in range(max_retries):
        try:
            # æ˜¾ç¤ºè¦ç¿»è¯‘çš„å†…å®¹é¢„è§ˆ
            preview = re.sub(r'<[^>]+>', '', current_block)[:50]
            print(f"  ğŸ“‹ å‘é€ç¿»è¯‘è¯·æ±‚ (å°è¯• {attempt+1}/{max_retries})")
            print(f"  ğŸ“ å†…å®¹é¢„è§ˆ: {preview}...")
            print(f"  â° è¯·æ±‚å‘é€æ—¶é—´: {time.strftime('%H:%M:%S')}")
            
            # ä½¿ç”¨è¿æ¥ç®¡ç†å™¨å‘é€æ¶ˆæ¯
            await connection_manager.send_message(prompt)
            response = ""
            start_time = time.time()
            message_count = 0
            tool_call_count = 0
            plan_message_count = 0
            current_agent_id = None
            sub_agents = set()

            # ä½¿ç”¨è¿æ¥ç®¡ç†å™¨è·å–æ¶ˆæ¯è¿­ä»£å™¨
            last_message_time = start_time
            MESSAGE_TIMEOUT = 30  # 30ç§’æ— æ–°æ¶ˆæ¯åˆ™è¶…æ—¶
            
            async for message in connection_manager.get_message_iterator():
                message_count += 1
                current_time = time.time()
                elapsed = current_time - start_time
                
                # å…¨å±€è¶…æ—¶æ£€æŸ¥ï¼ˆæ¯æ¡æ¶ˆæ¯éƒ½æ£€æŸ¥ï¼‰
                if elapsed > TIMEOUT_SEC:
                    print(f"  â±ï¸ å…¨å±€è¶…æ—¶: å·²ç­‰å¾… {elapsed:.1f}ç§’ > {TIMEOUT_SEC}ç§’")
                    raise SDKTimeoutError(f"ç¿»è¯‘è¶…æ—¶ (ç­‰å¾…äº† {elapsed:.1f}ç§’)")
                
                # æ¶ˆæ¯é—´è¶…æ—¶æ£€æŸ¥
                if current_time - last_message_time > MESSAGE_TIMEOUT:
                    print(f"  â±ï¸ æ¶ˆæ¯è¶…æ—¶: {current_time - last_message_time:.1f}ç§’æœªæ”¶åˆ°æ–°æ¶ˆæ¯")
                    raise SDKTimeoutError("æ¶ˆæ¯æ¥æ”¶è¶…æ—¶")
                
                last_message_time = current_time
                
                # æ¯10ç§’è¾“å‡ºä¸€æ¬¡è¿›åº¦ä¿¡æ¯
                if message_count == 1 or (message_count % 10 == 0):
                    print(f"  ğŸ“Š è¿›åº¦: å·²ç­‰å¾… {elapsed:.1f}ç§’, æ”¶åˆ° {message_count} æ¡æ¶ˆæ¯, å“åº”é•¿åº¦ {len(response)} å­—ç¬¦")
                
                # æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦åŒ…å«é”™è¯¯ä¿¡æ¯
                message_str = str(message)
                if "error" in message_str.lower() or "aborted" in message_str.lower():
                    print(f"  âŒ æ£€æµ‹åˆ°é”™è¯¯æˆ–ä¸­æ­¢æ¶ˆæ¯: {message_str[:100]}...")
                    raise ConnectionError(f"iFlowæœåŠ¡ç«¯é”™è¯¯: æ¶ˆæ¯åŒ…å«é”™è¯¯ä¿¡æ¯")
                
                if isinstance(message, AssistantMessage):
                    # åŠ¨æ€è·å– agent_id
                    if not current_agent_id:
                        current_agent_id = message.agent_id or "default"
                        if message.agent_id:
                            agent_name = str(message.agent_id)
                            print(f"  ğŸ¤– å½“å‰ Agent: {agent_name} (ID: {message.agent_id})")
                        else:
                            print(f"  ğŸ¤– å½“å‰ Agent: é»˜è®¤ç¿»è¯‘ä»£ç†")
                    
                    response += message.chunk.text
                    print(f"  ğŸ“ æ”¶åˆ°å“åº”ç‰‡æ®µ: {len(message.chunk.text)} å­—ç¬¦ (æ€»è®¡: {len(response)} å­—ç¬¦)")
                elif isinstance(message, ToolCallMessage):
                    tool_call_count += 1
                    # åŠ¨æ€è·å–å·¥å…·è°ƒç”¨ä¿¡æ¯
                    tool_name = getattr(message, 'label', 'Unknown')
                    tool_id = getattr(message, 'id', 'Unknown')
                    print(f"  ğŸ› ï¸ å·¥å…·è°ƒç”¨ #{tool_call_count}: {tool_name}")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰ sub agent ä¿¡æ¯
                    if hasattr(message, 'agent_id') and message.agent_id:
                        sub_agents.add(message.agent_id)
                    
                    # é™é»˜å¤„ç†å·¥å…·è°ƒç”¨æ¶ˆæ¯ï¼Œä¸è¾“å‡ºåˆ°ç¿»è¯‘ç»“æœ
                    pass
                elif isinstance(message, PlanMessage):
                    plan_message_count += 1
                    entries_count = len(message.entries) if hasattr(message, 'entries') else 0
                    print(f"  ğŸ“‹ è®¡åˆ’æ¶ˆæ¯ #{plan_message_count}: {entries_count} ä¸ªè®¡åˆ’é¡¹")
                    # é™é»˜å¤„ç†è®¡åˆ’æ¶ˆæ¯ï¼Œä¸è¾“å‡ºåˆ°ç¿»è¯‘ç»“æœ
                    pass
                elif isinstance(message, TaskFinishMessage):
                    print(f"  âœ… ä»»åŠ¡å®Œæˆ (å…±æ¥æ”¶ {message_count} æ¡æ¶ˆæ¯)")
                    if sub_agents:
                        print(f"  ğŸ”„ ä½¿ç”¨çš„ Sub Agents: {', '.join(sub_agents)}")
                    
                    # å¤„ç† TaskFinishMessage ä¸­çš„ stopReason ä¿¡æ¯
                    stop_reason = getattr(message, 'stop_reason', None)
                    print(f"  ğŸ“‹ ç»“æŸåŸå› : {stop_reason}")
                    
                    # æ ¹æ®ç»“æŸåŸå› è¿›è¡Œä¸åŒå¤„ç†
                    try:
                        session_reset_needed = False
                        if stop_reason == StopReason.MAX_TOKENS:
                            print(f"  âš ï¸ è­¦å‘Š: ç¿»è¯‘ç»“æœå¯èƒ½è¢«æˆªæ–­ï¼Œå› ä¸ºè¾¾åˆ°äº†æœ€å¤§ä»¤ç‰Œé™åˆ¶")
                            # è‡ªåŠ¨é‡ç½®ä¼šè¯ï¼Œç¡®ä¿åç»­ç¿»è¯‘æœ‰å……è¶³çš„ä¸Šä¸‹æ–‡ç©ºé—´
                            print(f"  ğŸ”„ è‡ªåŠ¨é‡ç½®ä¼šè¯ï¼Œä¸ºåç»­ç¿»è¯‘å‡†å¤‡å……è¶³çš„ä¸Šä¸‹æ–‡ç©ºé—´")
                            await connection_manager.reset_session()
                            session_reset_needed = True
                        elif stop_reason == StopReason.END_TURN:
                            print(f"  ğŸ“Š ç¿»è¯‘æ­£å¸¸å®Œæˆ")
                        else:
                            print(f"  â„¹ï¸ ç¿»è¯‘ä»¥å…¶ä»–åŸå› ç»“æŸ: {stop_reason}")
                    except (ValueError, TypeError):
                        # å¦‚æœ StopReason ä¸åŒ¹é…ï¼Œä½¿ç”¨å­—ç¬¦ä¸²æ¯”è¾ƒä½œä¸ºå¤‡é€‰
                        stop_reason_str = str(stop_reason).upper()
                        session_reset_needed = False
                        if 'MAX_TOKENS' in stop_reason_str:
                            print(f"  âš ï¸ è­¦å‘Š: ç¿»è¯‘ç»“æœå¯èƒ½è¢«æˆªæ–­ï¼Œå› ä¸ºè¾¾åˆ°äº†æœ€å¤§ä»¤ç‰Œé™åˆ¶")
                            # è‡ªåŠ¨é‡ç½®ä¼šè¯ï¼Œç¡®ä¿åç»­ç¿»è¯‘æœ‰å……è¶³çš„ä¸Šä¸‹æ–‡ç©ºé—´
                            print(f"  ğŸ”„ è‡ªåŠ¨é‡ç½®ä¼šè¯ï¼Œä¸ºåç»­ç¿»è¯‘å‡†å¤‡å……è¶³çš„ä¸Šä¸‹æ–‡ç©ºé—´")
                            await connection_manager.reset_session()
                            session_reset_needed = True
                        elif 'END_TURN' in stop_reason_str:
                            print(f"  ğŸ“Š ç¿»è¯‘æ­£å¸¸å®Œæˆ")
                        else:
                            print(f"  â„¹ï¸ ç¿»è¯‘ä»¥å…¶ä»–åŸå› ç»“æŸ: {stop_reason}")
                    
                    # ä»»åŠ¡å®Œæˆæ¶ˆæ¯ï¼Œä¸è¾“å‡ºåˆ°ç¿»è¯‘ç»“æœ
                    break
                else:
                    # æœªçŸ¥æ¶ˆæ¯ç±»å‹ï¼Œè®°å½•ä½†ä¸å½±å“æµç¨‹
                    print(f"  ğŸ“¨ æ”¶åˆ°æœªçŸ¥ç±»å‹æ¶ˆæ¯: {type(message).__name__}")

            # å¤„ç†ä¼šè¯é‡ç½®éœ€æ±‚
            if 'session_reset_needed' in locals() and session_reset_needed:
                # å¦‚æœä¼šè¯è¢«é‡ç½®ï¼Œå½“å‰ç¿»è¯‘å¯èƒ½ä¸å®Œæ•´ï¼Œéœ€è¦é‡æ–°å°è¯•
                print(f"  ğŸ”„ å°†é‡æ–°ç¿»è¯‘å½“å‰å—ä»¥ç¡®ä¿å®Œæ•´æ€§")
                if attempt < max_retries - 1:
                    # ç»§ç»­é‡è¯•å¾ªç¯ï¼Œé‡æ–°ç¿»è¯‘å½“å‰å—
                    await asyncio.sleep(1)  # çŸ­æš‚ç­‰å¾…ï¼Œç¡®ä¿é‡ç½®å®Œæˆ
                    continue
                else:
                    print(f"  âš ï¸ è­¦å‘Š: è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œå½“å‰å—å¯èƒ½ç¿»è¯‘ä¸å®Œæ•´")

            # æ¸…ç†å“åº”ï¼šåªä¿ç•™ HTML å—ï¼ˆç®€å•ç­–ç•¥ï¼‰
            response = response.strip()
            if response.startswith("```") and response.endswith("```"):
                response = "\n".join(response.split("\n")[1:-1])

            # å…³é”®ä¿®æ”¹ï¼šå¤„ç†çº¯æ–‡æœ¬ç¿»è¯‘ç»“æœ
            if response and "<" not in response:
                print(f"  âš ï¸ è­¦å‘Š: ç¿»è¯‘ç»“æœæ˜¯çº¯æ–‡æœ¬ï¼Œè‡ªåŠ¨åŒ…è£…HTMLæ ‡ç­¾")
                print(f"  ğŸ“ åŸå§‹å“åº”å†…å®¹: {repr(response[:100])}")
                
                # å¦‚æœæå–åˆ°äº†åŸå—æ ‡ç­¾ï¼Œä½¿ç”¨åŸæ ‡ç­¾åŒ…è£…
                if original_tag and tag_name:
                    response = f"{original_tag}{leading_spaces}{response}{trailing_spaces}{closing_tag}"
                    print(f"  âœ… ä½¿ç”¨åŸå—æ ‡ç­¾åŒ…è£…: {original_tag.strip()}")
                    print(f"  ğŸ“ æ¢å¤å‰åç©ºæ ¼: å‰ '{repr(leading_spaces)}', å '{repr(trailing_spaces)}'")
                else:
                    # é»˜è®¤ä½¿ç”¨<p>æ ‡ç­¾åŒ…è£…
                    response = f"<p>{response}</p>"
                    print(f"  âœ… ä½¿ç”¨é»˜è®¤<p>æ ‡ç­¾åŒ…è£…")
            
            # ä¼˜åŒ–åçš„åŸºç¡€éªŒè¯
            if not response:
                print(f"  âš ï¸ è­¦å‘Š: ç¿»è¯‘ç»“æœæ— æ•ˆ - é•¿åº¦: {len(response) if response else 0}")
                print(f"  ğŸ“ åŸå§‹å“åº”å†…å®¹: {repr(response[:100]) if response else 'None'}")
                # è¿”å›åŸå§‹å†…å®¹è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…ç¨‹åºå´©æºƒ
                return f"<!-- ç¿»è¯‘å¤±è´¥: æ— æ•ˆç¿»è¯‘ç»“æœ -->"

            print(f"  ğŸ“Š ç¿»è¯‘å®Œæˆ: {len(response)} å­—ç¬¦")
            return response

        except (Exception, asyncio.CancelledError) as e:
            elapsed = time.time() - start_time if 'start_time' in locals() else 0
            msg_count = message_count if 'message_count' in locals() else 0
            print(f"  âš ï¸ ç¿»è¯‘å¤±è´¥ (å°è¯• {attempt+1}/{max_retries})")
            print(f"  âŒ é”™è¯¯ç±»å‹: {type(e).__name__}")
            print(f"  âŒ é”™è¯¯è¯¦æƒ…: {str(e)}")
            print(f"  â±ï¸ å·²ç­‰å¾…æ—¶é—´: {elapsed:.1f}ç§’")
            print(f"  ğŸ“¨ å·²æ¥æ”¶æ¶ˆæ¯: {msg_count}æ¡")
            
            # ç‰¹æ®Šå¤„ç†è¶…æ—¶é”™è¯¯å’Œè¿æ¥é”™è¯¯
            if isinstance(e, SDKTimeoutError) or isinstance(e, ConnectionError) or "timeout" in str(e).lower():
                print(f"  ğŸš¨ æ£€æµ‹åˆ°è¶…æ—¶æˆ–è¿æ¥é”™è¯¯ï¼Œå°è¯•é‡å¯iFlowè¿›ç¨‹...")
                try:
                    # æ–­å¼€å½“å‰è¿æ¥
                    await connection_manager.disconnect()
                    # é‡å¯iFlowè¿›ç¨‹
                    await connection_manager._check_and_restart_iflow_process()
                    # é‡æ–°å»ºç«‹è¿æ¥
                    await connection_manager.connect()
                    print(f"  âœ… iFlowè¿›ç¨‹é‡å¯æˆåŠŸ")
                except Exception as restart_e:
                    print(f"  âš ï¸ é‡å¯iFlowè¿›ç¨‹æ—¶å‡ºé”™: {restart_e}")
            
            # ç‰¹æ®Šå¤„ç†iFlowå†…éƒ¨é”™è¯¯
            if "operation was aborted" in str(e).lower() or "internal error" in str(e).lower():
                print(f"  ğŸš¨ æ£€æµ‹åˆ°iFlowæœåŠ¡ç«¯å†…éƒ¨é”™è¯¯ï¼Œå¯èƒ½éœ€è¦é‡å¯æœåŠ¡æˆ–ç¨åé‡è¯•")
                if attempt == max_retries - 1:
                    error_info = f"IFLOW_INTERNAL_ERROR: {str(e)}"
                    return f"<!-- {error_info} -->"
                # å¯¹äºå†…éƒ¨é”™è¯¯ï¼Œå¢åŠ ç­‰å¾…æ—¶é—´
                wait_time = 5 * (attempt + 1)
                print(f"  â³ iFlowå†…éƒ¨é”™è¯¯ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                await asyncio.sleep(wait_time)
                continue
                
            if attempt == max_retries - 1:
                error_info = f"TRANSLATION_FAILED after {max_retries} attempts: {type(e).__name__} - {str(e)}"
                return f"<!-- {error_info} -->"
            print(f"  ğŸ”„ ç­‰å¾… 2 ç§’åé‡è¯•...")
            await asyncio.sleep(2)
    
    # ç¡®ä¿å‡½æ•°æ€»æ˜¯è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œå³ä½¿æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
    return f"<!-- ç¿»è¯‘å¤±è´¥: æ‰€æœ‰é‡è¯•å°è¯•å‡å¤±è´¥ -->"

# ======================
# ä¸»æµç¨‹
# ======================

def extract_translatable_blocks_by_type(content: str, file_type: str) -> List[str]:
    """
    æ ¹æ®æ–‡ä»¶ç±»å‹æå–å¯ç¿»è¯‘çš„æ–‡æœ¬å—
    """
    if file_type == 'html':
        return extract_translatable_blocks(content)
    elif file_type == 'ncx':
        return extract_translatable_blocks_ncx(content)
    elif file_type == 'opf':
        return extract_translatable_blocks_opf(content)
    else:
        # å¯¹äºå…¶ä»–ç±»å‹çš„æ–‡ä»¶ï¼Œæš‚æ—¶è¿”å›ç©ºåˆ—è¡¨
        return []

def normalize_html_whitespace(html: str) -> str:
    """è§„èŒƒåŒ–HTMLä¸­çš„ç©ºç™½å­—ç¬¦ï¼Œç”¨äºæ¯”è¾ƒ"""
    import re
    # ç§»é™¤æ ‡ç­¾ä¹‹é—´çš„å¤šä½™ç©ºç™½
    html = re.sub(r'>\s+<', '><', html)
    # è§„èŒƒåŒ–æ ‡ç­¾å†…çš„ç©ºç™½
    html = re.sub(r'\s+', ' ', html)
    return html.strip()

def update_file_content_by_type_incremental(
    current_content: str, 
    file_type: str, 
    original_block: str, 
    translated_block: str,
    block_index: int
) -> str:
    """
    å¢é‡æ›´æ–°ï¼šåªæ›´æ–°å½“å‰ç¿»è¯‘çš„å—ï¼Œè€Œä¸æ˜¯é‡æ–°æ„å»ºæ•´ä¸ªæ–‡ä»¶
    
    Args:
        current_content: å½“å‰æ–‡ä»¶å†…å®¹ï¼ˆå¯èƒ½åŒ…å«å·²ç¿»è¯‘çš„éƒ¨åˆ†ï¼‰
        file_type: æ–‡ä»¶ç±»å‹
        original_block: åŸå§‹å—å†…å®¹
        translated_block: ç¿»è¯‘åçš„å—å†…å®¹
        block_index: å½“å‰å—çš„ç´¢å¼•
    
    Returns:
        æ›´æ–°åçš„æ–‡ä»¶å†…å®¹
    """
    import re
    if file_type == 'html':
        # æ£€æŸ¥translated_blockæ˜¯å¦ä¸ºNone
        if translated_block is None:
            print(f"  âš ï¸ è­¦å‘Š: translated_blockä¸ºNoneï¼Œè·³è¿‡æ›¿æ¢")
            return current_content
        
        # æ£€æŸ¥åŸå§‹å—æ˜¯å¦å·²ç»åŒ…å«bilingual-containerï¼Œå¦‚æœåŒ…å«åˆ™è·³è¿‡å¤„ç†ï¼Œé¿å…åµŒå¥—
        if 'bilingual-container' in original_block:
            print(f"  âš ï¸ è­¦å‘Š: åŸå§‹å—å·²åŒ…å«bilingual-containerï¼Œè·³è¿‡å¤„ç†")
            return current_content
        
        # æ£€æŸ¥åŸå§‹å—æ˜¯å¦å·²ç»è¢«å¤„ç†è¿‡ï¼ˆåŒ…å«original-textæˆ–translated-textç±»ï¼‰
        if 'original-text' in original_block or 'translated-text' in original_block:
            print(f"  âš ï¸ è­¦å‘Š: åŸå§‹å—å·²åŒ…å«ç¿»è¯‘ç›¸å…³ç±»ï¼Œè·³è¿‡å¤„ç†")
            return current_content
            
        # å¯¹äºHTMLï¼Œå…ˆå°è¯•ç›´æ¥æ›¿æ¢
        if original_block in current_content:
            # å®ç°åŒè¯­å¯¹ç…§ï¼šä¿ç•™åŸæ–‡ï¼Œæ·»åŠ è¯‘æ–‡ï¼Œå¹¶æ·»åŠ æ ·å¼ç±»åŒºåˆ†
            # ä¸ºåŸæ–‡æ·»åŠ  original-text ç±»
            # ä¿®å¤æ­£åˆ™è¡¨è¾¾å¼ï¼šæ­£ç¡®å¤„ç†å·²æœ‰classå±æ€§çš„æƒ…å†µ
            def add_class_to_tag(match):
                tag_name = match.group(1)
                attributes = match.group(2)
                content = match.group(3)
                
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰classå±æ€§
                if 'class=' in attributes:
                    # æå–å·²æœ‰classå€¼
                    class_match = re.search(r'class="([^"]*)"', attributes)
                    if class_match:
                        existing_classes = class_match.group(1)
                        # å¦‚æœå·²æœ‰original-textç±»ï¼Œåˆ™ä¸é‡å¤æ·»åŠ 
                        if 'original-text' in existing_classes:
                            return match.group(0)
                        # åˆå¹¶classå±æ€§
                        new_classes = f"{existing_classes} original-text"
                        # ä¿®å¤å¼•å·åµŒå¥—é—®é¢˜
                        new_class_attr = 'class="' + new_classes + '"'
                        updated_attrs = attributes.replace(class_match.group(0), new_class_attr)
                        return '<' + tag_name + updated_attrs + '>' + content + '</' + tag_name + '>'
                # æ²¡æœ‰classå±æ€§ï¼Œç›´æ¥æ·»åŠ 
                return f'<{tag_name}{attributes} class="original-text">{content}</{tag_name}>'
            
            original_with_class = re.sub(r'<([a-z0-9]+)([^>]*)>(.*)</\1>', add_class_to_tag, original_block, flags=re.DOTALL | re.IGNORECASE)
            if original_with_class == original_block:  # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°æ ‡ç­¾
                original_with_class = f'<div class="original-text">{original_block}</div>'
            
            # ä¸ºè¯‘æ–‡æ·»åŠ  translated-text ç±»
            def add_translated_class_to_tag(match):
                tag_name = match.group(1)
                attributes = match.group(2)
                content = match.group(3)
                
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰classå±æ€§
                if 'class=' in attributes:
                    # æå–å·²æœ‰classå€¼
                    class_match = re.search(r'class="([^"]*)"', attributes)
                    if class_match:
                        existing_classes = class_match.group(1)
                        # å¦‚æœå·²æœ‰translated-textç±»ï¼Œåˆ™ä¸é‡å¤æ·»åŠ 
                        if 'translated-text' in existing_classes:
                            return match.group(0)
                        # åˆå¹¶classå±æ€§
                        new_classes = f"{existing_classes} translated-text"
                        # ä¿®å¤å¼•å·åµŒå¥—é—®é¢˜
                        new_class_attr = 'class="' + new_classes + '"'
                        updated_attrs = attributes.replace(class_match.group(0), new_class_attr)
                        return '<' + tag_name + updated_attrs + '>' + content + '</' + tag_name + '>'
                # æ²¡æœ‰classå±æ€§ï¼Œç›´æ¥æ·»åŠ 
                return f'<{tag_name}{attributes} class="translated-text">{content}</{tag_name}>'
            
            translated_with_class = re.sub(r'<([a-z0-9]+)([^>]*)>(.*)</\1>', add_translated_class_to_tag, translated_block, flags=re.DOTALL | re.IGNORECASE)
            if translated_with_class == translated_block:  # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°æ ‡ç­¾
                translated_with_class = f'<div class="translated-text">{translated_block}</div>'
            
            bilingual_block = f'<div class="bilingual-container">{original_with_class}{translated_with_class}</div>'
            print(f"  ğŸ”„ å®ç°HTMLåŒè¯­å¯¹ç…§: æ›¿æ¢åŸå§‹å—ä¸ºåŒè¯­å—ï¼Œæ·»åŠ æ ·å¼åŒºåˆ†")
            return current_content.replace(original_block, bilingual_block, 1)
        else:
            # å¦‚æœç›´æ¥æ›¿æ¢å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ–‡æœ¬å†…å®¹åŒ¹é…
            from bs4 import BeautifulSoup
            
            try:
                # è§£æå½“å‰å†…å®¹
                soup = BeautifulSoup(current_content, 'html.parser')
                orig_soup = BeautifulSoup(original_block, 'html.parser')
                orig_tag = orig_soup.find()
                
                if orig_tag:
                    # è·å–åŸå§‹å—çš„æ–‡æœ¬å†…å®¹ï¼ˆç”¨äºåŒ¹é…ï¼‰
                    orig_text = orig_tag.get_text()
                    
                    # åœ¨æ–‡æ¡£ä¸­æŸ¥æ‰¾åŒ…å«ç›¸åŒæ–‡æœ¬çš„æ ‡ç­¾
                    tags_found = []
                    for tag in soup.find_all(orig_tag.name):
                        if tag.get_text() == orig_text:
                            tags_found.append(tag)
                    
                    # å¦‚æœæ‰¾åˆ°å¤šä¸ªåŒ¹é…ï¼Œä½¿ç”¨ç´¢å¼•æ¥ç¡®å®šæ˜¯å“ªä¸€ä¸ª
                    if tags_found:
                        target_tag = tags_found[min(block_index, len(tags_found)-1)]
                        
                        # æ›¿æ¢ä¸ºåŒè¯­å¯¹ç…§ç»“æ„
                        trans_soup = BeautifulSoup(translated_block, 'html.parser')
                        trans_tag = trans_soup.find()
                        if trans_tag:
                            # åˆ›å»ºåŒè¯­å¯¹ç…§å®¹å™¨
                            from bs4 import Tag
                            bilingual_container = Tag(name='div')
                            bilingual_container['class'] = ['bilingual-container']
                            # ä¿ç•™åŸæ–‡ï¼Œæ·»åŠ è¯‘æ–‡ï¼Œå¹¶æ·»åŠ æ ·å¼ç±»åŒºåˆ†
                            # ä¸ºåŸæ–‡æ·»åŠ  original-text ç±»
                            if 'class' in target_tag.attrs:
                                if 'original-text' not in target_tag.attrs['class']:
                                    target_tag.attrs['class'].append('original-text')
                            else:
                                target_tag.attrs['class'] = ['original-text']
                            
                            # ä¸ºè¯‘æ–‡æ·»åŠ  translated-text ç±»
                            if 'class' in trans_tag.attrs:
                                if 'translated-text' not in trans_tag.attrs['class']:
                                    trans_tag.attrs['class'].append('translated-text')
                            else:
                                trans_tag.attrs['class'] = ['translated-text']
                            
                            bilingual_container.append(target_tag)
                            bilingual_container.append(trans_tag)
                            # æ›¿æ¢åŸæ ‡ç­¾ä¸ºåŒè¯­å¯¹ç…§å®¹å™¨
                            target_tag.replace_with(bilingual_container)
                            print(f"  ğŸ”„ é€šè¿‡BeautifulSoupå®ç°HTMLåŒè¯­å¯¹ç…§")
                            return str(soup)
                
                # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè®°å½•è­¦å‘Šä½†ä¸ä¿®æ”¹å†…å®¹
                print(f"  âš ï¸ è­¦å‘Šï¼šå— {block_index} æ›¿æ¢å¤±è´¥ï¼Œä¿æŒåŸæ ·")
                return current_content
                
            except Exception as e:
                print(f"  âŒ å— {block_index} æ›´æ–°æ—¶å‡ºé”™: {str(e)}")
                return current_content
    
    elif file_type == 'ncx':
        # å¯¹äºNCXï¼Œå®ç°åŒè¯­å¯¹ç…§ï¼šä¿ç•™åŸæ–‡ï¼Œæ·»åŠ è¯‘æ–‡
        import re
        # ä»ç¿»è¯‘åçš„å—ä¸­æå–æ–‡æœ¬
        trans_match = re.search(r'<text>(.*?)</text>', translated_block)
        if trans_match:
            trans_text = trans_match.group(1)
            # ä»åŸå§‹å—ä¸­æå–åŸå§‹æ–‡æœ¬
            orig_match = re.search(r'<text>(.*?)</text>', original_block)
            if orig_match:
                orig_text = orig_match.group(1)
                # å®ç°åŒè¯­å¯¹ç…§ï¼šä¿ç•™åŸæ–‡ï¼Œæ·»åŠ è¯‘æ–‡
                bilingual_text = f'<text>{orig_text} / {trans_text}</text>'
                # æ›¿æ¢å½“å‰å†…å®¹ä¸­çš„å¯¹åº”éƒ¨åˆ†
                print(f"  ğŸ”„ å®ç°NCXåŒè¯­å¯¹ç…§: {orig_text} -> {trans_text}")
                return current_content.replace(
                    f"<text>{orig_text}</text>",
                    bilingual_text,
                    1
                )
        return current_content
    
    elif file_type == 'opf':
        # å¯¹äºOPFï¼Œå®ç°åŒè¯­å¯¹ç…§ï¼šä¿ç•™åŸæ–‡ï¼Œæ·»åŠ è¯‘æ–‡
        import re
        # è¯†åˆ«æ ‡ç­¾ç±»å‹
        tag_match = re.search(r'<(\w+)>', original_block)
        if tag_match:
            tag_name = tag_match.group(1)
            # ä»ç¿»è¯‘åçš„å—ä¸­æå–æ–‡æœ¬
            trans_match = re.search(f'<{tag_name}>(.*?)</{tag_name}>', translated_block)
            if trans_match:
                trans_text = trans_match.group(1)
                # ä»åŸå§‹å—ä¸­æå–åŸå§‹æ–‡æœ¬
                orig_match = re.search(f'<{tag_name}>(.*?)</{tag_name}>', original_block)
                if orig_match:
                    orig_text = orig_match.group(1)
                    # å®ç°åŒè¯­å¯¹ç…§ï¼šä¿ç•™åŸæ–‡ï¼Œæ·»åŠ è¯‘æ–‡
                    bilingual_text = f'<{tag_name}>{orig_text} / {trans_text}</{tag_name}>'
                    # æ›¿æ¢å½“å‰å†…å®¹ä¸­çš„å¯¹åº”éƒ¨åˆ†
                    print(f"  ğŸ”„ å®ç°OPFåŒè¯­å¯¹ç…§: {tag_name}æ ‡ç­¾ - {orig_text} -> {trans_text}")
                    return current_content.replace(
                        f"<{tag_name}>{orig_text}</{tag_name}>",
                        bilingual_text,
                        1
                    )
        return current_content
    
    return current_content

def update_file_content_by_type(original_content: str, file_type: str, original_blocks: List[str], translated_blocks: List[str]) -> str:
    """
    æ ¹æ®ç¿»è¯‘åçš„å—æ›´æ–°åŸå§‹æ–‡ä»¶å†…å®¹ï¼ˆä¿ç•™æ­¤å‡½æ•°ç”¨äºå‘åå…¼å®¹ï¼‰
    """
    updated_content = original_content
    
    for i, (orig_block, trans_block) in enumerate(zip(original_blocks, translated_blocks)):
        updated_content = update_file_content_by_type_incremental(
            updated_content, file_type, orig_block, trans_block, i
        )
    
    return updated_content

async def main():
    print("ğŸš€ å¯åŠ¨ iFlow EPUB ç¿»è¯‘å™¨ï¼ˆå®Œæ•´EPUBç»“æ„ç¿»è¯‘ï¼‰")
    print("ğŸ“‹ ç¿»è¯‘æ¨¡å¼: ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç¿»è¯‘ï¼Œä¿æŒHTMLç»“æ„")
    print("ğŸ”§ é…ç½®: æœ€å¤§é‡è¯•æ¬¡æ•°={}, è¶…æ—¶æ—¶é—´={}ç§’".format(MAX_RETRY, TIMEOUT_SEC))
    
    # åˆå§‹åŒ–å¢å¼ºçš„æ—¥å¿—ç³»ç»Ÿ
    enhanced_logger = EnhancedLogger("EPUBTranslator", LOG_FILE, LOG_LEVEL)
    enhanced_logger.logger.info("EPUBç¿»è¯‘å™¨å¯åŠ¨")
    enhanced_logger.logger.info(f"é…ç½®ä¿¡æ¯ - è¶…æ—¶: {TIMEOUT_SEC}ç§’, é‡è¯•: {MAX_RETRY}æ¬¡")
    
    # åˆå§‹åŒ–èµ„æºç›‘æ§å™¨
    resource_monitor = ResourceMonitor(
        max_memory_mb=MAX_MEMORY_MB,
        warning_threshold=MEMORY_WARNING_THRESHOLD
    )
    
    # æ·»åŠ èµ„æºæ¸…ç†å›è°ƒ
    def cleanup_beautifulsoup_cache():
        """æ¸…ç†BeautifulSoupç¼“å­˜"""
        import bs4
        if hasattr(bs4, '_cached_html5_parser'):
            bs4._cached_html5_parser.clear()
    
    resource_monitor.add_cleanup_callback(cleanup_beautifulsoup_cache)
    
    # å¯åŠ¨èµ„æºç›‘æ§
    await resource_monitor.start_monitoring()
    print("ğŸ“Š èµ„æºç›‘æ§å·²å¯åŠ¨")

    # åŠ è½½çŠ¶æ€
    progress_data = load_json(PROGRESS_FILE, {})
    error_log = load_json(ERROR_LOG_FILE, {"errors": []})
    new_terms = load_json(NEW_TERMS_FILE, {"discovered_terms": []})
    glossary = load_glossary()
    
    # åˆå§‹åŒ–è¿›åº¦æ•°æ®ç»“æ„
    if not progress_data or 'meta' not in progress_data:
        progress_data = {
            "meta": {
                "total_files": 0,
                "completed_files": 0,
                "total_blocks": 0,
                "completed_blocks": 0,
                "last_updated": time.strftime("%Y-%m-%dT%H:%M:%SZ")
            },
            "files": {}
        }
    
    # ç¡®ä¿æ‰€æœ‰æ–‡ä»¶éƒ½æœ‰æ­£ç¡®çš„å­—æ®µå’Œç»Ÿè®¡ä¿¡æ¯
    completed_files_count = 0
    total_blocks = 0
    completed_blocks = 0
    
    for file_key, file_progress in progress_data["files"].items():
        # è·å–å½“å‰æ–‡ä»¶çš„å—æ•°ä¿¡æ¯
        file_total_blocks = file_progress.get("total_blocks", 0)
        file_completed = file_progress.get("completed", [])
        file_completed_blocks = len(file_completed)
        
        # æ›´æ–°æ€»å—æ•°ç»Ÿè®¡
        total_blocks += file_total_blocks
        completed_blocks += file_completed_blocks
        
        # æ›´æ–°æ–‡ä»¶çš„å—æ•°ä¿¡æ¯
        file_progress["completed_blocks"] = file_completed_blocks
        
        # ç¡®å®šæ–‡ä»¶æ˜¯å¦å·²å®Œæˆ
        if file_total_blocks > 0:
            file_progress["is_completed"] = (file_completed_blocks == file_total_blocks)
        else:
            file_progress["is_completed"] = True
        
        # ç»Ÿè®¡å·²å®Œæˆæ–‡ä»¶
        if file_progress["is_completed"]:
            completed_files_count += 1
    
    # æ›´æ–°å…ƒæ•°æ®ç»Ÿè®¡
    total_files = len(progress_data["files"])
    progress_data["meta"]["total_files"] = total_files
    progress_data["meta"]["completed_files"] = completed_files_count
    progress_data["meta"]["total_blocks"] = total_blocks
    progress_data["meta"]["completed_blocks"] = completed_blocks
    progress_data["meta"]["last_updated"] = time.strftime("%Y-%m-%dT%H:%M:%SZ")
    
    # è·å–æ‰€æœ‰å¾…ç¿»è¯‘æ–‡ä»¶ï¼ˆé€’å½’éå†æ•´ä¸ªsourceç›®å½•ï¼‰
    all_files = []    # é€’å½’éå†æ•´ä¸ª source/ ç›®å½•æ ‘
    for file_path in SOURCE_ROOT.rglob("*"):
        if file_path.is_file():
            # è·å–ç›¸å¯¹äº SOURCE_ROOT çš„ç›¸å¯¹è·¯å¾„
            rel_path = file_path.relative_to(SOURCE_ROOT)
            all_files.append(str(rel_path))
    
    # æŒ‰å­—æ¯é¡ºåºæ’åºï¼Œä¿è¯å¤„ç†é¡ºåºä¸€è‡´
    all_files.sort()
        
    if not all_files:
        print("âŒ æœªæ‰¾åˆ° source/ ç›®å½•ä¸­çš„æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„")
        return
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦é¢„ç”Ÿæˆè¿›åº¦æ•°æ®ï¼ˆæ–‡ä»¶å­˜åœ¨ä¸”æœ‰å†…å®¹æ—¶ç›´æ¥ä½¿ç”¨ï¼‰
    progress_file_exists = os.path.exists(PROGRESS_FILE) and os.path.getsize(PROGRESS_FILE) > 0
    
    # å¦‚æœè¿›åº¦æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ•°æ®ä¸ºç©ºï¼Œé¢„æ‰«ææ‰€æœ‰æ–‡ä»¶ç”Ÿæˆå®Œæ•´è¿›åº¦æ•°æ®
    if not progress_file_exists or (not progress_data["files"] and all_files):
        print("ğŸ” é¢„æ‰«ææ‰€æœ‰æ–‡ä»¶ï¼Œç”Ÿæˆå®Œæ•´è¿›åº¦æ•°æ®...")
        
        # åˆå§‹åŒ–å˜é‡
        total_blocks = 0
        completed_files = set()
        
        for filename in all_files:
            file_type = get_file_type(filename)
            source_path = SOURCE_ROOT / filename
            
            # åˆå§‹åŒ–æ–‡ä»¶è¿›åº¦
            if filename not in progress_data["files"]:
                progress_data["files"][filename] = {
                    "type": file_type,
                    "total_blocks": 0,
                    "completed_blocks": 0,
                    "completed": [],
                    "failed": [],
                    "current_position": 0,
                    "is_completed": False
                }
                progress_data["meta"]["total_files"] += 1
            
            # å¯¹äºå¯ç¿»è¯‘çš„æ–‡ä»¶ï¼Œé¢„æå–å—æ•°
            if file_type in ['html', 'ncx', 'opf'] and source_path.exists():
                try:
                    original_content = source_path.read_text(encoding='utf-8')
                    blocks = extract_translatable_blocks_by_type(original_content, file_type)
                    
                    # æ›´æ–°æ–‡ä»¶æ€»å—æ•°
                    file_total_blocks = len(blocks)
                    progress_data["files"][filename]["total_blocks"] = file_total_blocks
                    total_blocks += file_total_blocks
                except Exception as e:
                    print(f"  âš ï¸ é¢„æ‰«ææ–‡ä»¶ {filename} æ—¶å‡ºé”™: {str(e)}")
                    continue
            else:
                # éæ–‡æœ¬æ–‡ä»¶é»˜è®¤å®Œæˆ
                progress_data["files"][filename]["is_completed"] = True
                completed_files.add(filename)
        
        # æ›´æ–°æ€»å—æ•°
        progress_data["meta"]["total_blocks"] = total_blocks
        progress_data["meta"]["last_updated"] = time.strftime("%Y-%m-%dT%H:%M:%SZ")
        
        # ä¿å­˜é¢„ç”Ÿæˆçš„è¿›åº¦æ•°æ®
        save_json(progress_data, PROGRESS_FILE)
        print("âœ… é¢„æ‰«æå®Œæˆï¼Œè¿›åº¦æ•°æ®å·²ä¿å­˜")
    
    # ä»è¿›åº¦æ•°æ®ä¸­æ„å»ºcompleted_filesé›†åˆ
    completed_files = set()
    if progress_data and 'files' in progress_data:
        for file_key, file_progress in progress_data["files"].items():
            if file_progress.get("is_completed", False):
                completed_files.add(file_key)
    
    # åˆå§‹åŒ– checklist
    update_checklist(all_files, progress_data)
    


    # åˆ›å»ºè¿æ¥ç®¡ç†å™¨å¹¶å¤„ç†è¿æ¥é—®é¢˜
    connection_manager = None
    
    # ä¸»å¾ªç¯ï¼šå¤„ç†æ‰€æœ‰æ–‡ä»¶ï¼Œæ”¯æŒè¿æ¥ç®¡ç†å™¨è‡ªåŠ¨é‡å»º
    all_files_completed = False
    while True:
        try:
            # å¦‚æœè¿æ¥ç®¡ç†å™¨ä¸å­˜åœ¨æˆ–æœªè¿æ¥ï¼Œåˆ›å»ºæ–°çš„è¿æ¥ç®¡ç†å™¨
            if not connection_manager or not connection_manager.is_connected:
                connection_manager = await create_connection_manager_with_retry(
                    max_retries=5, 
                    delay=3, 
                    timeout=IFLOW_TIMEOUT,
                    logger=enhanced_logger
                )
                print("ğŸ”Œ å·²è¿æ¥åˆ° iFlow æœåŠ¡")
            
            for file_idx, filename in enumerate(all_files, 1):
                file_type = get_file_type(filename)
                print(f"\n{'='*60}")
                print(f"ğŸ“„ å¤„ç†æ–‡ä»¶ [{file_idx}/{len(all_files)}]: {filename}")
                print(f"ğŸ“‹ æ–‡ä»¶ç±»å‹: {file_type}")
                print(f"ğŸ“Š æ€»ä½“è¿›åº¦: {len(completed_files)}/{len(all_files)} æ–‡ä»¶å·²å®Œæˆ ({len(completed_files)/len(all_files)*100:.1f}%)")
                print(f"â° å½“å‰æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
                file_key = filename

                # æ„å»ºæºè·¯å¾„å’Œç›®æ ‡è·¯å¾„
                source_path = SOURCE_ROOT / filename
                dest_path = TRANSLATED_ROOT / filename

                # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
                dest_path.parent.mkdir(parents=True, exist_ok=True)

                if not source_path.exists():
                    print(f"  âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                    continue
                
                # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
                file_size = source_path.stat().st_size
                print(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚ ({file_size/1024:.1f} KB)")

                # ç¡®ä¿æ–‡ä»¶è¿›åº¦æ•°æ®å­˜åœ¨ï¼ˆé˜²æ­¢é¢„æ‰«ææ—¶é—æ¼æŸäº›æ–‡ä»¶ï¼‰
                if file_key not in progress_data["files"]:
                    print(f"  âš ï¸ æ–‡ä»¶ {file_key} ä¸åœ¨è¿›åº¦æ•°æ®ä¸­ï¼Œé‡æ–°åˆå§‹åŒ–")
                    progress_data["files"][file_key] = {
                        "type": file_type,
                        "total_blocks": 0,
                        "completed_blocks": 0,
                        "completed": [],
                        "failed": [],
                        "current_position": 0,
                        "is_completed": False
                    }
                    progress_data["meta"]["total_files"] += 1

                # æ ¹æ®æ–‡ä»¶ç±»å‹å†³å®šå¦‚ä½•å¤„ç†
                if file_type in ['html', 'ncx', 'opf']:
                    # å¯ç¿»è¯‘çš„æ–‡æœ¬æ–‡ä»¶
                    original_content = source_path.read_text(encoding='utf-8')
                    
                    # æ ¹æ®æ–‡ä»¶ç±»å‹æå–å¯ç¿»è¯‘å—
                    blocks = extract_translatable_blocks_by_type(original_content, file_type)
                    
                    # æ›´æ–°æ€»å—æ•°ï¼ˆå¦‚æœæœ‰å˜åŒ–ï¼‰
                    current_total_blocks = progress_data["files"][file_key]["total_blocks"]
                    if current_total_blocks == 0 or current_total_blocks != len(blocks):
                        # è®¡ç®—å—æ•°å˜åŒ–
                        old_total = current_total_blocks
                        progress_data["files"][file_key]["total_blocks"] = len(blocks)
                        progress_data["meta"]["total_blocks"] += (len(blocks) - old_total)
                        print(f"  ğŸ”„ æ›´æ–°æ–‡ä»¶å—æ•°: {old_total} â†’ {len(blocks)}")

                    # å‡†å¤‡ç›®æ ‡å†…å®¹ï¼šå¦‚æœå·²æœ‰éƒ¨åˆ†ç¿»è¯‘ï¼Œä»ç¿»è¯‘æ–‡ä»¶è¯»å–ï¼›å¦åˆ™ä»åŸæ–‡å¼€å§‹
                    completed_blocks = len(progress_data["files"][file_key]["completed"])
                    if dest_path.exists() and completed_blocks > 0:
                        print(f"  ğŸ”„ æ£€æµ‹åˆ°éƒ¨åˆ†ç¿»è¯‘è¿›åº¦ï¼Œä»å·²ç¿»è¯‘æ–‡ä»¶æ¢å¤")
                        translated_content = dest_path.read_text(encoding='utf-8')
                        
                        # éªŒè¯å·²ç¿»è¯‘æ–‡ä»¶æ˜¯å¦çœŸçš„åŒ…å«ç¿»è¯‘å†…å®¹
                        sample_jp_check = contains_japanese(translated_content[:500])  # æ£€æŸ¥å‰500å­—ç¬¦
                        if sample_jp_check:
                            print(f"  âš ï¸ è­¦å‘Šï¼šå·²ç¿»è¯‘æ–‡ä»¶ä¼¼ä¹ä»åŒ…å«å¤§é‡æ—¥æ–‡ï¼Œå¯èƒ½éœ€è¦é‡æ–°ç¿»è¯‘")
                            # å¯ä»¥é€‰æ‹©ä»åŸæ–‡é‡æ–°å¼€å§‹ï¼Œæˆ–ç»§ç»­å°è¯•æ¢å¤
                            # è¿™é‡Œé€‰æ‹©ç»§ç»­ï¼Œä½†ä¼šåœ¨åç»­ç¿»è¯‘ä¸­è¦†ç›–æ—¥æ–‡éƒ¨åˆ†
                        
                        # åˆå§‹åŒ–translated_blocksæ•°ç»„
                        translated_blocks = [""] * len(blocks)
                        
                        # å¯¹äºå·²å®Œæˆçš„å—ï¼Œä¿æŒä¸ºç©ºå­—ç¬¦ä¸²ï¼ˆä¼šåœ¨å¢é‡æ›´æ–°æ—¶ä»æ–‡ä»¶ä¸­è¯»å–ï¼‰
                        # å¯¹äºæœªå®Œæˆçš„å—ï¼Œä¹Ÿä¿æŒä¸ºç©ºå­—ç¬¦ä¸²
                        print(f"  ğŸ“‹ å·²å®Œæˆ {completed_blocks} ä¸ªå—ï¼Œå°†åœ¨ç¿»è¯‘æ—¶é€ä¸ªæ›´æ–°")
                    else:
                        print(f"  ğŸ†• é¦–æ¬¡ç¿»è¯‘æ­¤æ–‡ä»¶")
                        translated_content = original_content
                        translated_blocks = [""] * len(blocks)

                    # å¦‚æœæœ‰éœ€è¦ç¿»è¯‘çš„å—ï¼Œåˆ™è¿›è¡Œç¿»è¯‘
                    if len(blocks) > 0:
                        # é€å—å¤„ç†
                        block_start_time = time.time()
                        for i, block in enumerate(blocks):
                            if i in progress_data["files"][file_key]["completed"]:
                                print(f"  âœ… è·³è¿‡å·²ç¿»è¯‘å— {i+1}/{len(blocks)}")
                                # å¦‚æœå—å·²ç¿»è¯‘ï¼Œä»æ–‡ä»¶ä¸­æ¢å¤å·²ç¿»è¯‘çš„å—å†…å®¹
                                translated_blocks[i] = block
                                continue

                            # è®¡ç®—è¿›åº¦å’Œé¢„è®¡æ—¶é—´
                            completed_count = len(progress_data["files"][file_key]["completed"])
                            remaining = len(blocks) - completed_count
                            if completed_count > 0:
                                elapsed = time.time() - block_start_time
                                avg_time = elapsed / completed_count
                                eta_seconds = avg_time * remaining
                                eta_str = f"{int(eta_seconds//60)}åˆ†{int(eta_seconds%60)}ç§’"
                            else:
                                eta_str = "è®¡ç®—ä¸­..."
                            
                            print(f"\n  {'â”€'*50}")
                            print(f"  ğŸ”¤ ç¿»è¯‘å— [{i+1}/{len(blocks)}] (å‰©ä½™ {remaining} å—)")
                            print(f"  â±ï¸ é¢„è®¡å‰©ä½™æ—¶é—´: {eta_str}")
                            
                            # æ˜¾ç¤ºå—å†…å®¹é¢„è§ˆ
                            block_preview = re.sub(r'<[^>]+>', '', block)[:80]
                            print(f"  ğŸ“ å†…å®¹é¢„è§ˆ: {block_preview}...")
                            print(f"  ğŸ“ å—é•¿åº¦: {len(block)} å­—ç¬¦")

                            # å‡†å¤‡ä¸Šä¸‹æ–‡
                            prev_blk, curr_blk, next_blk = build_context(blocks, i)

                            # è°ƒç”¨ç¿»è¯‘
                            translate_start = time.time()
                            translated_block = await translate_block(
                                connection_manager, curr_blk, prev_blk, next_blk, glossary
                            )
                            translate_duration = time.time() - translate_start
                            print(f"  â±ï¸ ç¿»è¯‘è€—æ—¶: {translate_duration:.1f}ç§’")

                            # å­˜å‚¨ç¿»è¯‘åçš„å—
                            translated_blocks[i] = translated_block

                            # æ£€æŸ¥ç¿»è¯‘ç»“æœæ˜¯å¦æœ‰æ•ˆ
                            if translated_block is None:
                                print(f"  âš ï¸ è­¦å‘Š: ç¬¬{i+1}å—ç¿»è¯‘ç»“æœä¸ºNone")
                                print(f"  ğŸ›‘ ç¨‹åºå°†é€€å‡ºï¼Œä¸å†ç»§ç»­ç¿»è¯‘")
                                raise Exception(f"ç¿»è¯‘å¤±è´¥: ç¬¬{i+1}å—ç¿»è¯‘ç»“æœä¸ºNone")
                            
                            # æ£€æŸ¥æ˜¯å¦æ˜¯ç¿»è¯‘å¤±è´¥çš„æ³¨é‡Š
                            if "TRANSLATION_FAILED" in translated_block or "ç¿»è¯‘å¤±è´¥" in translated_block:
                                print(f"  âš ï¸ è­¦å‘Š: ç¬¬{i+1}å—ç¿»è¯‘å¤±è´¥")
                                print(f"  ğŸ›‘ ç¨‹åºå°†é€€å‡ºï¼Œä¸å†ç»§ç»­ç¿»è¯‘")
                                raise Exception(f"ç¿»è¯‘å¤±è´¥: ç¬¬{i+1}å—ç¿»è¯‘å¤±è´¥")

                            # å¢é‡æ›´æ–°ï¼šåªæ›´æ–°å½“å‰ç¿»è¯‘çš„å—
                            if dest_path.exists():
                                # ä»å·²ç¿»è¯‘çš„æ–‡ä»¶ä¸­è¯»å–å½“å‰å†…å®¹
                                current_content = dest_path.read_text(encoding='utf-8')
                            else:
                                # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸå§‹å†…å®¹
                                current_content = original_content
                            
                            # ä½¿ç”¨å¢é‡æ›´æ–°å‡½æ•°åªæ›¿æ¢å½“å‰å—
                            updated_content = update_file_content_by_type_incremental(
                                current_content, file_type, blocks[i], translated_block, i
                            )

                            # ç«‹å³å†™å…¥æ–‡ä»¶ï¼ˆç°åœ¨åªå†™å…¥æ›´æ–°åçš„å†…å®¹ï¼‰
                            try:
                                # åˆ›å»ºå¤‡ä»½ï¼ˆå¦‚æœåŸæ–‡ä»¶å­˜åœ¨ï¼‰
                                backup_path = dest_path.with_suffix(dest_path.suffix + '.backup')
                                if dest_path.exists():
                                    import shutil
                                    shutil.copy2(dest_path, backup_path)
                                
                                # å†™å…¥æ›´æ–°åçš„å†…å®¹
                                dest_path.write_text(updated_content, encoding='utf-8')
                                
                                # éªŒè¯å†™å…¥æ˜¯å¦æˆåŠŸ
                                written_content = dest_path.read_text(encoding='utf-8')
                                if len(written_content) == 0:
                                    raise IOError("å†™å…¥çš„æ–‡ä»¶ä¸ºç©º")
                                
                                # æ›´æ–°å†…å­˜ä¸­çš„å†…å®¹ï¼Œç”¨äºåç»­å¤„ç†
                                translated_content = updated_content
                                
                                # åˆ é™¤å¤‡ä»½æ–‡ä»¶ï¼ˆå†™å…¥æˆåŠŸï¼‰
                                if backup_path.exists():
                                    backup_path.unlink()
                                
                            except Exception as write_error:
                                print(f"  âŒ æ–‡ä»¶å†™å…¥å¤±è´¥: {str(write_error)}")
                                print(f"  ğŸ”„ å°è¯•æ¢å¤...")
                                
                                # å¦‚æœæœ‰å¤‡ä»½ï¼Œæ¢å¤å¤‡ä»½
                                if 'backup_path' in locals() and backup_path.exists():
                                    import shutil
                                    shutil.copy2(backup_path, dest_path)
                                    backup_path.unlink()
                                    print(f"  âœ… å·²ä»å¤‡ä»½æ¢å¤")
                                else:
                                    print(f"  âš ï¸ æ— æ³•æ¢å¤ï¼Œæ²¡æœ‰å¯ç”¨çš„å¤‡ä»½")
                                
                                # è®°å½•é”™è¯¯
                                error_log["errors"].append({
                                    "file": filename,
                                    "block": i,
                                    "error": f"æ–‡ä»¶å†™å…¥å¤±è´¥: {str(write_error)}",
                                    "content": translated_block
                                })
                                save_json(error_log, ERROR_LOG_FILE)
                                
                                # è·³è¿‡å½“å‰å—çš„è¿›åº¦æ›´æ–°ï¼Œä½†ç»§ç»­ç¿»è¯‘ä¸‹ä¸€ä¸ªå—
                                print(f"  â±ï¸ è·³è¿‡å— {i} çš„è¿›åº¦æ›´æ–°ï¼Œç»§ç»­ä¸‹ä¸€ä¸ªå—")
                                continue
                            
                            # è´¨é‡æ£€æŸ¥ï¼ˆåªæœ‰å†™å…¥æˆåŠŸåæ‰æ‰§è¡Œï¼‰
                            if contains_japanese(translated_block):
                                err_msg = f"å— {i} ä»å«æ—¥æ–‡å­—ç¬¦"
                                print(f"  âŒ {err_msg}")
                                error_log["errors"].append({
                                    "file": filename,
                                    "block": i,
                                    "error": err_msg,
                                    "content": translated_block
                                })
                                save_json(error_log, ERROR_LOG_FILE)

                            if not check_chinese_punctuation(translated_block):
                                print(f"  âš ï¸ å— {i} å¯èƒ½ä½¿ç”¨äº†æ—¥æ–‡æ ‡ç‚¹")

                            # æ–‡ä»¶å†™å…¥æˆåŠŸåï¼Œå†æ›´æ–°è¿›åº¦ï¼ˆç¡®ä¿è¿›åº¦ä¸æ–‡ä»¶çŠ¶æ€åŒæ­¥ï¼‰
                            file_progress = progress_data["files"][file_key]
                            
                            # åªåœ¨å—æœªæ ‡è®°ä¸ºå®Œæˆæ—¶æ·»åŠ 
                            if i not in file_progress["completed"]:
                                file_progress["completed"].append(i)
                                file_progress["completed_blocks"] += 1
                                progress_data["meta"]["completed_blocks"] += 1
                            
                            file_progress["current_position"] = i
                            
                            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å®Œæˆ
                            total_blocks = file_progress["total_blocks"]
                            if total_blocks > 0:
                                file_progress["is_completed"] = (file_progress["completed_blocks"] == total_blocks)
                            else:
                                file_progress["is_completed"] = True
                            
                            # æ›´æ–°å…ƒæ•°æ®ä¸­çš„å®Œæˆæ–‡ä»¶è®¡æ•°
                            if file_progress["is_completed"] and file_key not in completed_files:
                                progress_data["meta"]["completed_files"] += 1
                            
                            # æ›´æ–°æœ€åä¿®æ”¹æ—¶é—´
                            progress_data["meta"]["last_updated"] = time.strftime("%Y-%m-%dT%H:%M:%SZ")
                            
                            # ä¿å­˜è¿›åº¦æ•°æ®
                            save_json(progress_data, PROGRESS_FILE)

                            print(f"  ğŸ’¾ å·²ä¿å­˜ {filename}ï¼ˆè¿›åº¦ {i+1}/{len(blocks)}ï¼‰")
                    else:
                        print(f"  â„¹ï¸ æ–‡ä»¶ä¸­æ²¡æœ‰éœ€è¦ç¿»è¯‘çš„å†…å®¹: {filename}")
                        # ä»ç„¶ä¿å­˜æ–‡ä»¶
                        dest_path.write_text(original_content, encoding='utf-8')
                else:
                    # éæ–‡æœ¬æ–‡ä»¶ï¼ˆå¦‚å›¾ç‰‡ã€CSSç­‰ï¼‰ï¼Œç›´æ¥å¤åˆ¶
                    print(f"  ğŸ“ å¤åˆ¶éæ–‡æœ¬æ–‡ä»¶: {filename}")
                    import shutil
                    shutil.copy2(source_path, dest_path)
                    
                    # æ›´æ–°éæ–‡æœ¬æ–‡ä»¶çš„è¿›åº¦çŠ¶æ€
                    file_progress = progress_data["files"][file_key]
                    file_progress["is_completed"] = True
                    file_progress["total_blocks"] = 0
                    file_progress["completed_blocks"] = 0
                    file_progress["completed"] = []
                    
                    # æ›´æ–°å…ƒæ•°æ®
                    if file_key not in completed_files:
                        progress_data["meta"]["completed_files"] += 1
                
                # æ›´æ–°æœ€åä¿®æ”¹æ—¶é—´
                progress_data["meta"]["last_updated"] = time.strftime("%Y-%m-%dT%H:%M:%SZ")
                
                # ä¿å­˜è¿›åº¦æ•°æ®
                save_json(progress_data, PROGRESS_FILE)

                # æ–‡ä»¶å®Œæˆ
                completed_files.add(filename)
                update_checklist(all_files, progress_data)
                print(f"âœ… å®Œæˆæ–‡ä»¶: {filename}")

                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ–‡ä»¶éƒ½å·²å®Œæˆ
                if len(completed_files) == len(all_files):
                    print("\nğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæ¯•ï¼")
                    print(f"è¾“å‡ºç›®å½•: {TRANSLATED_ROOT.absolute()}")
                    all_files_completed = True
                    break
            
            # å¦‚æœæ‰€æœ‰æ–‡ä»¶å·²å®Œæˆï¼Œé€€å‡ºå¤–å±‚å¾ªç¯
            if all_files_completed:
                break
        except (SDKTimeoutError, ConnectionError) as e:
            # å¤„ç†è¿æ¥é”™è¯¯ï¼Œéœ€è¦é‡å»ºè¿æ¥ç®¡ç†å™¨
            print(f"  ğŸš¨ è¿æ¥å¤±è´¥ï¼Œå°è¯•é‡å»ºè¿æ¥ç®¡ç†å™¨: {e}")
            if connection_manager:
                try:
                    await connection_manager.disconnect()
                except:
                    pass
            connection_manager = None  # é‡ç½®è¿æ¥ç®¡ç†å™¨ï¼Œè§¦å‘é‡æ–°åˆ›å»º
            continue  # ç»§ç»­å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„è¿æ¥ç®¡ç†å™¨
        except Exception as e:
            # å¤„ç†å…¶ä»–å¼‚å¸¸ï¼Œé€€å‡ºå¾ªç¯
            print(f"  ğŸš¨ å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            break

    # ç¡®ä¿è¿æ¥ç®¡ç†å™¨è¢«æ­£ç¡®å…³é—­
    try:
        if connection_manager:
            await connection_manager.disconnect()
            print("ğŸ”Œ è¿æ¥ç®¡ç†å™¨å·²æ–­å¼€")
    except Exception as e:
        print(f"âš ï¸ æ–­å¼€è¿æ¥ç®¡ç†å™¨æ—¶å‡ºé”™: {e}")
        pass  # å¿½ç•¥å…³é—­æ—¶çš„é”™è¯¯

    # åœæ­¢èµ„æºç›‘æ§å¹¶è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    try:
        if 'resource_monitor' in locals():
            await resource_monitor.stop_monitoring()
            
            # è¾“å‡ºå†…å­˜ç»Ÿè®¡ä¿¡æ¯
            memory_stats = resource_monitor.get_memory_stats()
            if memory_stats:
                print(f"\nğŸ“Š èµ„æºä½¿ç”¨ç»Ÿè®¡:")
                print(f"  å½“å‰å†…å­˜: {memory_stats['current_mb']:.1f}MB")
                print(f"  å³°å€¼å†…å­˜: {memory_stats['peak_mb']:.1f}MB")
                print(f"  å¹³å‡å†…å­˜: {memory_stats['avg_mb']:.1f}MB")
                print(f"  æœ€å¤§é™åˆ¶: {memory_stats['max_memory_mb']:.1f}MB")
                print(f"  ç›‘æ§æ ·æœ¬: {memory_stats['samples']} ä¸ª")
            
            print("ğŸ“Š èµ„æºç›‘æ§å·²åœæ­¢")
    except Exception as e:
        print(f"âš ï¸ åœæ­¢èµ„æºç›‘æ§æ—¶å‡ºé”™: {e}")
        pass

    # è¾“å‡ºè¿æ¥çŠ¶æ€æŠ¥å‘Š
    try:
        if 'enhanced_logger' in locals():
            connection_report = enhanced_logger.get_connection_report()
            print(f"\n{connection_report}")
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆè¿æ¥æŠ¥å‘Šæ—¶å‡ºé”™: {e}")
        pass

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­äº†ç¿»è¯‘è¿‡ç¨‹")
        print("âœ… è¿›åº¦å·²ä¿å­˜ï¼Œå¯ä»¥éšæ—¶æ¢å¤")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸ç»ˆæ­¢: {str(e)}")
        import traceback
        traceback.print_exc()
