#!/usr/bin/env python3
"""
iFlow CLI æ—¥æ–‡ EPUB ç¿»è¯‘å™¨ï¼ˆä¸¥æ ¼éµå¾ªç”¨æˆ· workflowï¼‰
ä½œè€…ï¼šQwen + ç”¨æˆ·è§„èŒƒ
"""

import asyncio
import json
import os
import re
import time
from pathlib import Path
from typing import List, Dict, Optional
from iflow_sdk import IFlowClient, AssistantMessage, TaskFinishMessage, TimeoutError as SDKTimeoutError, ToolCallMessage, PlanMessage

# ======================
# é…ç½®åŒºï¼ˆæŒ‰éœ€ä¿®æ”¹ï¼‰
# ======================
SOURCE_DIR = Path("source/OEBPS")
TRANSLATED_DIR = Path("translated")
CHECKLIST_FILE = "translate-checklist.md"
GLOSSARY_FILE = "glossary.md"
PROGRESS_FILE = "paragraph_progress.json"
ERROR_LOG_FILE = "error_log.json"
NEW_TERMS_FILE = "new_terms.json"

MAX_RETRY = 3
TIMEOUT_SEC = 60.0
QUALITY_CHECK_INTERVAL = 5

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
TRANSLATED_DIR.mkdir(exist_ok=True)

# ======================
# è¾…åŠ©å‡½æ•°
# ======================

def load_glossary() -> Dict[str, str]:
    """åŠ è½½æœ¯è¯­è¡¨ï¼šæ—¥æ–‡ -> ä¸­æ–‡"""
    if not os.path.exists(GLOSSARY_FILE):
        return {}
    glossary = {}
    with open(GLOSSARY_FILE, 'r', encoding='utf-8') as f:
        lines = f.readlines()
        for line in lines[2:]:  # è·³è¿‡æ ‡é¢˜è¡Œ
            if '|' in line:
                parts = line.strip().split('|')
                if len(parts) >= 3:
                    ja = parts[1].strip()
                    zh = parts[2].strip()
                    if ja and zh:
                        glossary[ja] = zh
    return glossary

def save_json(data, filepath: str):
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def load_json(filepath: str, default):
    if os.path.exists(filepath):
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    return default

def extract_translatable_blocks(html: str) -> List[str]:
    """æå–æ‰€æœ‰å¯ç¿»è¯‘çš„ HTML å—ï¼ˆä¿ç•™æ ‡ç­¾ï¼‰"""
    # ä½¿ç”¨ BeautifulSoup ä»¥æ›´å®‰å…¨åœ°è§£æ HTMLï¼Œé¿å…æ­£åˆ™è¡¨è¾¾å¼å¤„ç†å¤æ‚ HTML æ—¶çš„é—®é¢˜
    try:
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(html, 'html.parser')
        elements = soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'div'])
        return [str(elem) for elem in elements]
    except ImportError:
        # å¦‚æœæ²¡æœ‰å®‰è£…BeautifulSoupï¼Œåˆ™ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
        # åŒ¹é… <p>, <h1>-<h6>, <div>ï¼ˆå¸¦ class çš„å¸¸è§æ­£æ–‡å®¹å™¨ï¼‰
        pattern = r'(<(p|h[1-6]|div)(?:\s[^>]*)?>.*?</\2>)'
        matches = re.findall(pattern, html, re.DOTALL | re.IGNORECASE)
        return [m[0] for m in matches]

def build_context(blocks: List[str], idx: int) -> tuple:
    prev_block = blocks[idx - 1] if idx > 0 else ""
    curr_block = blocks[idx]
    next_block = blocks[idx + 1] if idx < len(blocks) - 1 else ""
    return prev_block, curr_block, next_block

def contains_japanese(text: str) -> bool:
    return bool(re.search(r'[\u3040-\u309F\u30A0-\u30FF\u3400-\u4DBF\u4E00-\u9FFF]', text))

def check_chinese_punctuation(text: str) -> bool:
    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ä¸­æ–‡æ ‡ç‚¹ï¼ˆç®€å•è§„åˆ™ï¼‰
    jp_punct = 'ã€‚ã€ãƒ»ã€Œã€ã€ã€ã€ã€‘ï¼ï¼Ÿ'
    for p in jp_punct:
        if p in text:
            return False
    return True

def update_checklist(file_list: List[str], completed_files: set):
    """æ›´æ–° translate-checklist.md"""
    content = "# æ—¥æ–‡ä¹¦ç±ç¿»è¯‘è¿›åº¦è¿½è¸ª\n\n## éœ€è¦ç¿»è¯‘çš„æ–‡ä»¶æ¸…å•\n\n### HTMLæ–‡ä»¶\n"
    for f in file_list:
        mark = "x" if f in completed_files else " "
        content += f"- [{mark}] {f}\n"
    content += "\n## ç¿»è¯‘è¿›åº¦ç»Ÿè®¡\n"
    total = len(file_list)
    done = len(completed_files)
    percent = done / total * 100 if total > 0 else 0
    content += f"- æ€»æ–‡ä»¶æ•°: {total}ä¸ªHTMLæ–‡ä»¶\n"
    content += f"- å·²ç¿»è¯‘: {done}ä¸ª\n"
    content += f"- å¾…ç¿»è¯‘: {total - done}ä¸ª\n"
    content += f"- å®Œæˆåº¦: {percent:.1f}%\n"
    with open(CHECKLIST_FILE, 'w', encoding='utf-8') as f:
        f.write(content)

# ======================
# æ ¸å¿ƒç¿»è¯‘å‡½æ•°
# ======================

async def translate_block_with_agent(
    client: IFlowClient,
    current_block: str,
    prev_block: str = "",
    next_block: str = "",
    glossary: Dict[str, str] = None,
    max_retries: int = MAX_RETRY
) -> str:
    """
    è°ƒç”¨ ja-zh-translator ç¿»è¯‘å•ä¸ª HTML å—
    """
    # æ„å»ºæœ¯è¯­æç¤º
    glossary_text = ""
    if glossary:
        terms = "\n".join([f"{ja} â†’ {zh}" for ja, zh in list(glossary.items())[:10]])  # é™åˆ¶é•¿åº¦
        glossary_text = f"\n\nè¯·ä¼˜å…ˆä½¿ç”¨ä»¥ä¸‹æœ¯è¯­ç¿»è¯‘ï¼š\n{terms}"

    # æ„å»ºä¸Šä¸‹æ–‡ï¼ˆæˆªæ–­é¿å…è¶…é•¿ï¼‰
    context_prompt = ""
    if prev_block or next_block:
        context_parts = []
        if prev_block:
            clean_prev = re.sub(r'<[^>]+>', '', prev_block)[:30]
            context_parts.append(f"å‰ä¸€æ®µï¼š{clean_prev}...")
        if next_block:
            clean_next = re.sub(r'<[^>]+>', '', next_block)[:30]
            context_parts.append(f"åä¸€æ®µï¼š{clean_next}...")
        context_prompt = "ä¸Šä¸‹æ–‡ï¼š" + "ï¼›".join(context_parts)

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ—¥ä¸­ç¿»è¯‘ä¸“å®¶ï¼ˆja-zh-translatorï¼‰ï¼Œè¯·ä¸¥æ ¼éµå®ˆï¼š
- ä»…è¾“å‡ºç¿»è¯‘åçš„ HTML æ®µè½ï¼Œä¸è¦ä»»ä½•è§£é‡Šã€æ³¨é‡Šæˆ–é¢å¤–æ–‡æœ¬
- ä¿æŒåŸå§‹ HTML æ ‡ç­¾ä¸å˜
- ä½¿ç”¨ä¸­æ–‡æ ‡ç‚¹ï¼ˆï¼Œã€‚ï¼ï¼Ÿï¼‰
- æ— æ—¥æ–‡å­—ç¬¦æ®‹ç•™
- è¯­æ°”è‡ªç„¶æµç•…ï¼Œç¬¦åˆä¸­æ–‡é˜…è¯»ä¹ æƒ¯{glossary_text}

{context_prompt}

ç°åœ¨ç¿»è¯‘ä»¥ä¸‹æ®µè½ï¼š
{current_block}
"""

    for attempt in range(max_retries):
        try:
            await client.send_message(prompt)
            response = ""
            start_time = time.time()

            async for message in client.receive_messages():
                if isinstance(message, AssistantMessage):
                    response += message.chunk.text
                    # é˜²æ­¢æ— é™ç­‰å¾…
                    if time.time() - start_time > TIMEOUT_SEC:
                        raise SDKTimeoutError("ç¿»è¯‘è¶…æ—¶")
                elif isinstance(message, ToolCallMessage):
                    # å¤„ç†å·¥å…·è°ƒç”¨æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                    print(f"  ğŸ› ï¸ å·¥å…·è°ƒç”¨: {message.label} (ID: {message.id})")
                    if message.content:
                        response += f"<!-- å·¥å…·è°ƒç”¨ç»“æœ: {message.content} -->"
                elif isinstance(message, PlanMessage):
                    # å¤„ç†è®¡åˆ’æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                    print(f"  ğŸ“‹ è®¡åˆ’æ¶ˆæ¯: {len(message.entries)} ä¸ªè®¡åˆ’é¡¹")
                    for entry in message.entries:
                        print(f"     - {entry.content}")
                elif isinstance(message, TaskFinishMessage):
                    break

            # æ¸…ç†å“åº”ï¼šåªä¿ç•™ HTML å—ï¼ˆç®€å•ç­–ç•¥ï¼‰
            response = response.strip()
            if response.startswith("```") and response.endswith("```"):
                response = "\n".join(response.split("\n")[1:-1])

            # åŸºç¡€éªŒè¯
            if not response or "<" not in response:
                raise ValueError("æ— æ•ˆç¿»è¯‘ç»“æœ")

            return response

        except (Exception, asyncio.CancelledError) as e:
            print(f"  âš ï¸ ç¿»è¯‘å¤±è´¥ (å°è¯• {attempt+1}/{max_retries}): {str(e)}")
            if attempt == max_retries - 1:
                return f"<!-- TRANSLATION_FAILED: {current_block} -->"
            await asyncio.sleep(2)

# ======================
# ä¸»æµç¨‹
# ======================

async def main():
    print("ğŸš€ å¯åŠ¨ iFlow EPUB ç¿»è¯‘å™¨ï¼ˆä¸¥æ ¼éµå¾ªç”¨æˆ· workflowï¼‰")

    # åŠ è½½çŠ¶æ€
    progress = load_json(PROGRESS_FILE, {})
    error_log = load_json(ERROR_LOG_FILE, {"errors": []})
    new_terms = load_json(NEW_TERMS_FILE, {"discovered_terms": []})
    glossary = load_glossary()

    # è·å–æ‰€æœ‰å¾…ç¿»è¯‘æ–‡ä»¶
    html_files = sorted([f.name for f in SOURCE_DIR.glob("text*.html")])
    if not html_files:
        print("âŒ æœªæ‰¾åˆ° source/OEBPS/text*.html æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„")
        return

    completed_files = set()

    # åˆå§‹åŒ– checklist
    update_checklist(html_files, completed_files)

    async with IFlowClient() as client:
        for html_file in html_files:
            print(f"\nğŸ“„ å¤„ç†æ–‡ä»¶: {html_file}")
            file_key = html_file

            # åˆå§‹åŒ–æ–‡ä»¶è¿›åº¦
            if file_key not in progress:
                progress[file_key] = {
                    "total_paragraphs": 0,
                    "completed": [],
                    "failed": [],
                    "current_position": 0
                }

            # è¯»å–æºæ–‡ä»¶
            source_path = SOURCE_DIR / html_file
            if not source_path.exists():
                print(f"  âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                continue

            original_content = source_path.read_text(encoding='utf-8')
            blocks = extract_translatable_blocks(original_content)
            progress[file_key]["total_paragraphs"] = len(blocks)

            # å‡†å¤‡ç›®æ ‡å†…å®¹ï¼ˆåˆå§‹ä¸ºåŸæ–‡ï¼‰
            translated_content = original_content

            # é€æ®µå¤„ç†
            for i, block in enumerate(blocks):
                if i in progress[file_key]["completed"]:
                    print(f"  âœ… è·³è¿‡å·²ç¿»è¯‘æ®µè½ {i+1}/{len(blocks)}")
                    continue

                print(f"  ğŸ”¤ ç¿»è¯‘æ®µè½ {i+1}/{len(blocks)}")

                # å‡†å¤‡ä¸Šä¸‹æ–‡
                prev_blk, curr_blk, next_blk = build_context(blocks, i)

                # è°ƒç”¨ç¿»è¯‘
                translated_block = await translate_block_with_agent(
                    client, curr_blk, prev_blk, next_blk, glossary
                )

                # æ›¿æ¢åˆ°å®Œæ•´å†…å®¹ï¼ˆåªæ›¿æ¢ç¬¬ä¸€æ¬¡å‡ºç°ï¼‰
                translated_content = translated_content.replace(curr_blk, translated_block, 1)

                # æ›´æ–°è¿›åº¦
                progress[file_key]["completed"].append(i)
                progress[file_key]["current_position"] = i
                save_json(progress, PROGRESS_FILE)

                # æ¯5æ®µä¿å­˜ä¸€æ¬¡æ–‡ä»¶ + è´¨é‡æ£€æŸ¥
                if (i + 1) % QUALITY_CHECK_INTERVAL == 0 or i == len(blocks) - 1:
                    # ä¿å­˜æ–‡ä»¶
                    output_path = TRANSLATED_DIR / html_file
                    output_path.write_text(translated_content, encoding='utf-8')

                    # è´¨é‡æ£€æŸ¥
                    if contains_japanese(translated_block):
                        err_msg = f"æ®µè½ {i} ä»å«æ—¥æ–‡å­—ç¬¦"
                        print(f"  âŒ {err_msg}")
                        error_log["errors"].append({
                            "file": html_file,
                            "paragraph": i,
                            "error": err_msg,
                            "content": translated_block
                        })
                        save_json(error_log, ERROR_LOG_FILE)

                    if not check_chinese_punctuation(translated_block):
                        print(f"  âš ï¸ æ®µè½ {i} å¯èƒ½ä½¿ç”¨äº†æ—¥æ–‡æ ‡ç‚¹")

                    print(f"  ğŸ’¾ å·²ä¿å­˜ {html_file}ï¼ˆè¿›åº¦ {i+1}/{len(blocks)}ï¼‰")

            # æ–‡ä»¶å®Œæˆ
            completed_files.add(html_file)
            update_checklist(html_files, completed_files)
            print(f"âœ… å®Œæˆæ–‡ä»¶: {html_file}")

    print("\nğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæ¯•ï¼")
    print(f"è¾“å‡ºç›®å½•: {TRANSLATED_DIR.absolute()}")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­äº†ç¿»è¯‘è¿‡ç¨‹")
        print("âœ… è¿›åº¦å·²ä¿å­˜ï¼Œå¯ä»¥éšæ—¶æ¢å¤")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸ç»ˆæ­¢: {str(e)}")
        import traceback
        traceback.print_exc()
